{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUeKVCYTbcyT"
   },
   "source": [
    "#### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2023-07-27T04:52:26.245942Z",
     "iopub.status.busy": "2023-07-27T04:52:26.245718Z",
     "iopub.status.idle": "2023-07-27T04:52:26.249405Z",
     "shell.execute_reply": "2023-07-27T04:52:26.248783Z"
    },
    "id": "4ellrPx7tdxq"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JfLUlawto_D"
   },
   "source": [
    "# Classification on imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DwdpaTKJOoPu"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/structured_data/imbalanced_data.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mthoSGBAOoX-"
   },
   "source": [
    "This tutorial demonstrates how to classify a highly imbalanced dataset in which the number of examples in one class greatly outnumbers the examples in another. You will work with the [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud) dataset hosted on Kaggle. The aim is to detect a mere 492 fraudulent transactions from 284,807 transactions in total. You will use [Keras](https://www.tensorflow.org/guide/keras/overview) to define the model and [class weights](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model) to help the model learn from the imbalanced data. .\n",
    "\n",
    "This tutorial contains complete code to:\n",
    "\n",
    "* Load a CSV file using Pandas.\n",
    "* Create train, validation, and test sets.\n",
    "* Define and train a model using Keras (including setting class weights).\n",
    "* Evaluate the model using various metrics (including precision and recall).\n",
    "* Select a threshold for a probabilistic classifier to get a deterministic classifier.\n",
    "* Try and compare with class weighted modelling and oversampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRHmSyHxEIhN"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:52:26.252994Z",
     "iopub.status.busy": "2023-07-27T04:52:26.252751Z",
     "iopub.status.idle": "2023-07-27T04:52:29.109039Z",
     "shell.execute_reply": "2023-07-27T04:52:29.108330Z"
    },
    "id": "JM7hDSNClfoK"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:52:29.114877Z",
     "iopub.status.busy": "2023-07-27T04:52:29.114443Z",
     "iopub.status.idle": "2023-07-27T04:52:29.118196Z",
     "shell.execute_reply": "2023-07-27T04:52:29.117608Z"
    },
    "id": "c8o1FHzD-_y_"
   },
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3iZVjziKHmX"
   },
   "source": [
    "## Data processing and exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sA9WOcmzH2D"
   },
   "source": [
    "### Download the Kaggle Credit Card Fraud data set\n",
    "\n",
    "Pandas is a Python library with many helpful utilities for loading and working with structured data. It can be used to download CSVs into a Pandas [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas.DataFrame).\n",
    "\n",
    "Note: This dataset has been collected and analysed during a research collaboration of Worldline and the [Machine Learning Group](http://mlg.ulb.ac.be) of ULB (Université Libre de Bruxelles) on big data mining and fraud detection. More details on current and past projects on related topics are available [here](https://www.researchgate.net/project/Fraud-detection-5) and the page of the [DefeatFraud](https://mlg.ulb.ac.be/wordpress/portfolio_page/defeatfraud-assessment-and-validation-of-deep-feature-engineering-and-learning-solutions-for-fraud-detection/) project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:52:29.121276Z",
     "iopub.status.busy": "2023-07-27T04:52:29.121042Z",
     "iopub.status.idle": "2023-07-27T04:52:32.041672Z",
     "shell.execute_reply": "2023-07-27T04:52:32.041080Z"
    },
    "id": "pR_SnbMArXr7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = tf.keras.utils\n",
    "raw_df = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:52:32.081175Z",
     "iopub.status.busy": "2023-07-27T04:52:32.080932Z",
     "iopub.status.idle": "2023-07-27T04:52:32.222164Z",
     "shell.execute_reply": "2023-07-27T04:52:32.221530Z"
    },
    "id": "-fgdQgmwUFuj"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.918649e-15</td>\n",
       "      <td>5.682686e-16</td>\n",
       "      <td>-8.761736e-15</td>\n",
       "      <td>2.811118e-15</td>\n",
       "      <td>-1.552103e-15</td>\n",
       "      <td>1.701640e-15</td>\n",
       "      <td>-3.662252e-16</td>\n",
       "      <td>-1.217809e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.918649e-15  5.682686e-16 -8.761736e-15  2.811118e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean  -1.552103e-15  1.701640e-15 -3.662252e-16 -1.217809e-16      88.349619   \n",
       "std    1.380247e+00  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.137433e+02 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -6.915971e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%   -5.433583e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    6.119264e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    3.480167e+01  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V26', 'V27', 'V28', 'Amount', 'Class']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWKB_CVZFLpB"
   },
   "source": [
    "### Examine the class label imbalance\n",
    "\n",
    "Let's look at the dataset imbalance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:52:32.226252Z",
     "iopub.status.busy": "2023-07-27T04:52:32.225609Z",
     "iopub.status.idle": "2023-07-27T04:52:32.230748Z",
     "shell.execute_reply": "2023-07-27T04:52:32.230141Z"
    },
    "id": "HCJFrtuY2iLF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 284807\n",
      "    Positive: 492 (0.17% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(raw_df['Class'])\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnLKFQDsCBUg"
   },
   "source": [
    "This shows the small fraction of positive samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qox6ryyzwdr"
   },
   "source": [
    "### Clean, split and normalize the data\n",
    "\n",
    "The raw data has a few issues. First the `Time` and `Amount` columns are too variable to use directly. Drop the `Time` column (since it's not clear what it means) and take the log of the `Amount` column to reduce its range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:52:32.234078Z",
     "iopub.status.busy": "2023-07-27T04:52:32.233620Z",
     "iopub.status.idle": "2023-07-27T04:52:32.273223Z",
     "shell.execute_reply": "2023-07-27T04:52:32.272622Z"
    },
    "id": "Ef42jTuxEjnj"
   },
   "outputs": [],
   "source": [
    "cleaned_df = raw_df.copy()\n",
    "\n",
    "# You don't want the `Time` column.\n",
    "cleaned_df.pop('Time')\n",
    "\n",
    "# The `Amount` column covers a huge range. Convert to log-space.\n",
    "eps = 0.001 # 0 => 0.1¢\n",
    "cleaned_df['Log Amount'] = np.log(cleaned_df.pop('Amount')+eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSNgdQFFFQ6u"
   },
   "source": [
    "Split the dataset into train, validation, and test sets. The validation set is used during the model fitting to evaluate the loss and any metrics, however the model is not fit with this data. The test set is completely unused during the training phase and is only used at the end to evaluate how well the model generalizes to new data. This is especially important with imbalanced datasets where [overfitting](https://developers.google.com/machine-learning/crash-course/generalization/peril-of-overfitting) is a significant concern from the lack of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:52:32.276435Z",
     "iopub.status.busy": "2023-07-27T04:52:32.276215Z",
     "iopub.status.idle": "2023-07-27T04:52:32.486567Z",
     "shell.execute_reply": "2023-07-27T04:52:32.485774Z"
    },
    "id": "xfxhKg7Yr1-b"
   },
   "outputs": [],
   "source": [
    "# Use a utility from sklearn to split and shuffle your dataset.\n",
    "train_df, test_df = train_test_split(cleaned_df, test_size=0.2)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "# Form np arrays of labels and features.\n",
    "train_labels = np.array(train_df.pop('Class'))\n",
    "bool_train_labels = train_labels != 0\n",
    "val_labels = np.array(val_df.pop('Class'))\n",
    "test_labels = np.array(test_df.pop('Class'))\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "val_features = np.array(val_df)\n",
    "test_features = np.array(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8a_Z_kBmr7Oh"
   },
   "source": [
    "We check whether the distribution of the classes in the three sets is about the same or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:52:32.490786Z",
     "iopub.status.busy": "2023-07-27T04:52:32.490286Z",
     "iopub.status.idle": "2023-07-27T04:52:32.494531Z",
     "shell.execute_reply": "2023-07-27T04:52:32.493905Z"
    },
    "id": "96520cffee66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average class probability in training set:   0.0018\n",
      "Average class probability in validation set: 0.0018\n",
      "Average class probability in test set:       0.0015\n"
     ]
    }
   ],
   "source": [
    "print(f'Average class probability in training set:   {train_labels.mean():.4f}')\n",
    "print(f'Average class probability in validation set: {val_labels.mean():.4f}')\n",
    "print(f'Average class probability in test set:       {test_labels.mean():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8a_Z_kBmr7Oh"
   },
   "source": [
    "Given the small number of positive labels, this seems about right.\n",
    "\n",
    "Normalize the input features using the sklearn StandardScaler.\n",
    "This will set the mean to 0 and standard deviation to 1.\n",
    "\n",
    "Note: The `StandardScaler` is only fit using the `train_features` to be sure the model is not peeking at the validation or test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:52:32.497916Z",
     "iopub.status.busy": "2023-07-27T04:52:32.497389Z",
     "iopub.status.idle": "2023-07-27T04:52:32.607809Z",
     "shell.execute_reply": "2023-07-27T04:52:32.607143Z"
    },
    "id": "IO-qEUmJ5JQg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (182276,)\n",
      "Validation labels shape: (45569,)\n",
      "Test labels shape: (56962,)\n",
      "Training features shape: (182276, 29)\n",
      "Validation features shape: (45569, 29)\n",
      "Test features shape: (56962, 29)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "\n",
    "val_features = scaler.transform(val_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "train_features = np.clip(train_features, -5, 5)\n",
    "val_features = np.clip(val_features, -5, 5)\n",
    "test_features = np.clip(test_features, -5, 5)\n",
    "\n",
    "\n",
    "print('Training labels shape:', train_labels.shape)\n",
    "print('Validation labels shape:', val_labels.shape)\n",
    "print('Test labels shape:', test_labels.shape)\n",
    "\n",
    "print('Training features shape:', train_features.shape)\n",
    "print('Validation features shape:', val_features.shape)\n",
    "print('Test features shape:', test_features.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XF2nNfWKJ33w"
   },
   "source": [
    "Caution: If you want to deploy a model, it's critical that you preserve the preprocessing calculations. The easiest way to implement them as layers, and attach them to your model before export.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQ7m9nqDC3W6"
   },
   "source": [
    "### Look at the data distribution\n",
    "\n",
    "Next compare the distributions of the positive and negative examples over a few features. Good questions to ask yourself at this point are:\n",
    "\n",
    "* Do these distributions make sense? \n",
    "    * Yes. You've normalized the input and these are mostly concentrated in the `+/- 2` range.\n",
    "* Can you see the difference between the distributions?\n",
    "    * Yes the positive examples contain a much higher rate of extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:52:32.611492Z",
     "iopub.status.busy": "2023-07-27T04:52:32.611239Z",
     "iopub.status.idle": "2023-07-27T04:52:34.540220Z",
     "shell.execute_reply": "2023-07-27T04:52:34.539542Z"
    },
    "id": "raK7hyjd_vf6"
   },
   "outputs": [],
   "source": [
    "pos_df = pd.DataFrame(train_features[ bool_train_labels], columns=train_df.columns)\n",
    "neg_df = pd.DataFrame(train_features[~bool_train_labels], columns=train_df.columns)\n",
    "\n",
    "sns.jointplot(x=pos_df['V5'], y=pos_df['V6'],\n",
    "              kind='hex', xlim=(-5,5), ylim=(-5,5))\n",
    "plt.suptitle(\"Positive distribution\")\n",
    "\n",
    "sns.jointplot(x=neg_df['V5'], y=neg_df['V6'],\n",
    "              kind='hex', xlim=(-5,5), ylim=(-5,5))\n",
    "_ = plt.suptitle(\"Negative distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFK1u4JX16D8"
   },
   "source": [
    "## Define the model and metrics\n",
    "\n",
    "Define a function that creates a simple neural network with a densly connected hidden layer, a [dropout](https://developers.google.com/machine-learning/glossary/#dropout_regularization) layer to reduce overfitting, and an output sigmoid layer that returns the probability of a transaction being fraudulent: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:52:34.543878Z",
     "iopub.status.busy": "2023-07-27T04:52:34.543340Z",
     "iopub.status.idle": "2023-07-27T04:52:37.944324Z",
     "shell.execute_reply": "2023-07-27T04:52:37.943478Z"
    },
    "id": "3JQDzUqT3UYG"
   },
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.BinaryCrossentropy(name='cross entropy'),  # same as model's loss\n",
    "      keras.metrics.MeanSquaredError(name='Brier score'),\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "def make_model(metrics=METRICS, output_bias=None):\n",
    "  if output_bias is not None:\n",
    "    output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "  model = keras.Sequential([\n",
    "      keras.layers.Dense(\n",
    "          16, activation='relu',\n",
    "          input_shape=(train_features.shape[-1],)),\n",
    "      keras.layers.Dropout(0.5),\n",
    "      keras.layers.Dense(1, activation='sigmoid',\n",
    "                         bias_initializer=output_bias),\n",
    "  ])\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=metrics)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SU0GX6E6mieP"
   },
   "source": [
    "### Understanding useful metrics\n",
    "\n",
    "Notice that there are a few metrics defined above that can be computed by the model that will be helpful when evaluating the performance.\n",
    "These can be divided into three groups.\n",
    "\n",
    "#### Metrics for probability predictions\n",
    "\n",
    "As we train our network with the cross entropy as a loss function, it is fully capable of predicting class probabilities, i.e. it is a probabilistic classifier.\n",
    "Good metrics to assess probabilistic predictions are, in fact, **proper scoring rules**. Their key property is that predicting the true probability is optimal. We give two well-known examples:\n",
    "\n",
    "*   **cross entropy** also known as log loss\n",
    "*   **Mean squared error** also known as the Brier score\n",
    "\n",
    "#### Metrics for deterministic 0/1 predictions\n",
    "\n",
    "In the end, one often wants to predict a class label, 0 or 1, *no fraud* or *fraud*.\n",
    "This is called a deterministic classifier.\n",
    "To get a label prediction from our probabilistic classifier, one needs to choose a probability threshold $t$.\n",
    "The default is to predict label 1 (fraud) if the predicted probability is larger than $t=50\\%$ and all the following metrics implicitly use this default. \n",
    "\n",
    "*   **False** negatives and **false** positives are samples that were **incorrectly** classified\n",
    "*   **True** negatives and **true** positives are samples that were **correctly** classified\n",
    "*   **Accuracy** is the percentage of examples correctly classified\n",
    ">   $\\frac{\\text{true samples}}{\\text{total samples}}$\n",
    "*   **Precision** is the percentage of **predicted** positives that were correctly classified\n",
    ">   $\\frac{\\text{true positives}}{\\text{true positives + false positives}}$\n",
    "*   **Recall** is the percentage of **actual** positives that were correctly classified\n",
    ">   $\\frac{\\text{true positives}}{\\text{true positives + false negatives}}$\n",
    "\n",
    "**Note:** Accuracy is not a helpful metric for this task. You can have 99.8%+ accuracy on this task by predicting False all the time.  \n",
    "\n",
    "#### Other metrices\n",
    "\n",
    "The following metrics take into account all possible choices of thresholds $t$.\n",
    "\n",
    "*   **AUC** refers to the Area Under the Curve of a Receiver Operating Characteristic curve (ROC-AUC). This metric is equal to the probability that a classifier will rank a random positive sample higher than a random negative sample.\n",
    "*   **AUPRC** refers to Area Under the Curve of the Precision-Recall Curve. This metric computes precision-recall pairs for different probability thresholds. \n",
    "\n",
    "\n",
    "#### Read more:\n",
    "*   [Strictly Proper Scoring Rules, Prediction, and Estimation](https://www.stat.washington.edu/people/raftery/Research/PDF/Gneiting2007jasa.pdf)\n",
    "*   [True vs. False and Positive vs. Negative](https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative)\n",
    "*   [Accuracy](https://developers.google.com/machine-learning/crash-course/classification/accuracy)\n",
    "*   [Precision and Recall](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall)\n",
    "*   [ROC-AUC](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)\n",
    "*   [Relationship between Precision-Recall and ROC Curves](https://www.biostat.wisc.edu/~page/rocpr.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYdhSAoaF_TK"
   },
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDbltVPg2m2q"
   },
   "source": [
    "### Build the model\n",
    "\n",
    "Now create and train your model using the function that was defined earlier. Notice that the model is fit using a larger than default batch size of 2048, this is important to ensure that each batch has a decent chance of containing a few positive samples. If the batch size was too small, they would likely have no fraudulent transactions to learn from.\n",
    "\n",
    "\n",
    "Note: Fitting this model will not handle the class imbalance efficiently. You will improve it later in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:52:37.948787Z",
     "iopub.status.busy": "2023-07-27T04:52:37.948535Z",
     "iopub.status.idle": "2023-07-27T04:52:37.952122Z",
     "shell.execute_reply": "2023-07-27T04:52:37.951548Z"
    },
    "id": "ouUkwPcGQsy3"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_prc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:52:37.955378Z",
     "iopub.status.busy": "2023-07-27T04:52:37.954834Z",
     "iopub.status.idle": "2023-07-27T04:52:38.017309Z",
     "shell.execute_reply": "2023-07-27T04:52:38.016738Z"
    },
    "id": "1xlR_dekzw7C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                480       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 497\n",
      "Trainable params: 497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wx7ND3_SqckO"
   },
   "source": [
    "Test run the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:52:38.023988Z",
     "iopub.status.busy": "2023-07-27T04:52:38.023487Z",
     "iopub.status.idle": "2023-07-27T04:52:38.483768Z",
     "shell.execute_reply": "2023-07-27T04:52:38.483115Z"
    },
    "id": "LopSd-yQqO3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60880435],\n",
       "       [0.37722972],\n",
       "       [0.45546705],\n",
       "       [0.62673116],\n",
       "       [0.6600403 ],\n",
       "       [0.38175252],\n",
       "       [0.24887452],\n",
       "       [0.27274162],\n",
       "       [0.33631015],\n",
       "       [0.56777644]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(train_features[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKIgWqHms_03"
   },
   "source": [
    "### Optional: Set the correct initial bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qk_3Ry6EoYDq"
   },
   "source": [
    "These initial guesses are not great. You know the dataset is imbalanced. Set the output layer's bias to reflect that, see [A Recipe for Training Neural Networks: \"init well\"](http://karpathy.github.io/2019/04/25/recipe/#2-set-up-the-end-to-end-trainingevaluation-skeleton--get-dumb-baselines). This can help with initial convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdbfWDuVpo6k"
   },
   "source": [
    "With the default bias initialization the loss should be about `math.log(2) = 0.69314` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:52:38.487533Z",
     "iopub.status.busy": "2023-07-27T04:52:38.487006Z",
     "iopub.status.idle": "2023-07-27T04:52:39.317152Z",
     "shell.execute_reply": "2023-07-27T04:52:39.316443Z"
    },
    "id": "H-oPqh3SoGXk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7353\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(train_features, train_labels, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hE-JRzfKqfhB"
   },
   "source": [
    "The correct bias to set can be derived from:\n",
    "\n",
    "$$ p_0 = pos/(pos + neg) = 1/(1+e^{-b_0}) $$\n",
    "$$ b_0 = -log_e(1/p_0 - 1) $$\n",
    "$$ b_0 = log_e(pos/neg)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:52:39.320881Z",
     "iopub.status.busy": "2023-07-27T04:52:39.320606Z",
     "iopub.status.idle": "2023-07-27T04:52:39.325507Z",
     "shell.execute_reply": "2023-07-27T04:52:39.324859Z"
    },
    "id": "F5KWPSjjstUS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.35935934])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_bias = np.log([pos/neg])\n",
    "initial_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1juXI9yY1KD"
   },
   "source": [
    "Set that as the initial bias, and the model will give much more reasonable initial guesses. \n",
    "\n",
    "It should be near: `pos/total = 0.0018`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:52:39.329002Z",
     "iopub.status.busy": "2023-07-27T04:52:39.328468Z",
     "iopub.status.idle": "2023-07-27T04:52:39.437069Z",
     "shell.execute_reply": "2023-07-27T04:52:39.436492Z"
    },
    "id": "50oyu1uss0i-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00036454],\n",
       "       [0.00113124],\n",
       "       [0.00057963],\n",
       "       [0.00173768],\n",
       "       [0.00159767],\n",
       "       [0.00132614],\n",
       "       [0.00077349],\n",
       "       [0.00038326],\n",
       "       [0.00046447],\n",
       "       [0.00104922]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_model(output_bias=initial_bias)\n",
    "model.predict(train_features[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xqFYb2KqRHQ"
   },
   "source": [
    "With this initialization the initial loss should be approximately:\n",
    "\n",
    "$$-p_0log(p_0)-(1-p_0)log(1-p_0) = 0.01317$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:52:39.440378Z",
     "iopub.status.busy": "2023-07-27T04:52:39.439899Z",
     "iopub.status.idle": "2023-07-27T04:52:40.207232Z",
     "shell.execute_reply": "2023-07-27T04:52:40.206435Z"
    },
    "id": "xVDqCWXDqHSc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0168\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(train_features, train_labels, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrDC8hvNr9yw"
   },
   "source": [
    "This initial loss is about 50 times less than it would have been with naive initialization.\n",
    "\n",
    "This way the model doesn't need to spend the first few epochs just learning that positive examples are unlikely. It also makes it easier to read plots of the loss during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EJj9ixKVBMT"
   },
   "source": [
    "### Checkpoint the initial weights\n",
    "\n",
    "To make the various training runs more comparable, keep this initial model's weights in a checkpoint file, and load them into each model before training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:52:40.210618Z",
     "iopub.status.busy": "2023-07-27T04:52:40.210155Z",
     "iopub.status.idle": "2023-07-27T04:52:40.245548Z",
     "shell.execute_reply": "2023-07-27T04:52:40.244848Z"
    },
    "id": "_tSUm4yAVIif"
   },
   "outputs": [],
   "source": [
    "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
    "model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVXiLyqyZ8AX"
   },
   "source": [
    "### Confirm that the bias fix helps\n",
    "\n",
    "Before moving on, confirm quick that the careful bias initialization actually helped.\n",
    "\n",
    "Train the model for 20 epochs, with and without this careful initialization, and compare the losses: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:52:40.248974Z",
     "iopub.status.busy": "2023-07-27T04:52:40.248530Z",
     "iopub.status.idle": "2023-07-27T04:52:50.279612Z",
     "shell.execute_reply": "2023-07-27T04:52:50.278770Z"
    },
    "id": "Dm4-4K5RZ63Q"
   },
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "model.load_weights(initial_weights)\n",
    "model.layers[-1].bias.assign([0.0])\n",
    "zero_bias_history = model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=20,\n",
    "    validation_data=(val_features, val_labels), \n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:52:50.283514Z",
     "iopub.status.busy": "2023-07-27T04:52:50.282885Z",
     "iopub.status.idle": "2023-07-27T04:53:00.173624Z",
     "shell.execute_reply": "2023-07-27T04:53:00.172789Z"
    },
    "id": "j8DsLXHQaSql"
   },
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "model.load_weights(initial_weights)\n",
    "careful_bias_history = model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=20,\n",
    "    validation_data=(val_features, val_labels), \n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:00.177792Z",
     "iopub.status.busy": "2023-07-27T04:53:00.177186Z",
     "iopub.status.idle": "2023-07-27T04:53:00.181762Z",
     "shell.execute_reply": "2023-07-27T04:53:00.181191Z"
    },
    "id": "E3XsMBjhauFV"
   },
   "outputs": [],
   "source": [
    "def plot_loss(history, label, n):\n",
    "  # Use a log scale on y-axis to show the wide range of values.\n",
    "  plt.semilogy(history.epoch, history.history['loss'],\n",
    "               color=colors[n], label='Train ' + label)\n",
    "  plt.semilogy(history.epoch, history.history['val_loss'],\n",
    "               color=colors[n], label='Val ' + label,\n",
    "               linestyle=\"--\")\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:00.184914Z",
     "iopub.status.busy": "2023-07-27T04:53:00.184651Z",
     "iopub.status.idle": "2023-07-27T04:53:00.573662Z",
     "shell.execute_reply": "2023-07-27T04:53:00.573032Z"
    },
    "id": "dxFaskm7beC7"
   },
   "outputs": [],
   "source": [
    "plot_loss(zero_bias_history, \"Zero Bias\", 0)\n",
    "plot_loss(careful_bias_history, \"Careful Bias\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKMioV0ddG3R"
   },
   "source": [
    "The above figure makes it clear: In terms of validation loss, on this problem, this careful initialization gives a clear advantage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsA_7SEntRaV"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:00.577533Z",
     "iopub.status.busy": "2023-07-27T04:53:00.576963Z",
     "iopub.status.idle": "2023-07-27T04:53:13.362671Z",
     "shell.execute_reply": "2023-07-27T04:53:13.361766Z"
    },
    "id": "yZKAc8NCDnoR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "90/90 [==============================] - 2s 10ms/step - loss: 0.0129 - cross entropy: 0.0109 - Brier score: 0.0014 - tp: 85.0000 - fp: 27.0000 - tn: 227414.0000 - fn: 319.0000 - accuracy: 0.9985 - precision: 0.7589 - recall: 0.2104 - auc: 0.7291 - prc: 0.2831 - val_loss: 0.0069 - val_cross entropy: 0.0069 - val_Brier score: 0.0014 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 45489.0000 - val_fn: 80.0000 - val_accuracy: 0.9982 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9246 - val_prc: 0.5963\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0084 - cross entropy: 0.0084 - Brier score: 0.0013 - tp: 85.0000 - fp: 18.0000 - tn: 181934.0000 - fn: 239.0000 - accuracy: 0.9986 - precision: 0.8252 - recall: 0.2623 - auc: 0.8271 - prc: 0.4158 - val_loss: 0.0043 - val_cross entropy: 0.0043 - val_Brier score: 8.5773e-04 - val_tp: 45.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 35.0000 - val_accuracy: 0.9990 - val_precision: 0.8036 - val_recall: 0.5625 - val_auc: 0.9310 - val_prc: 0.7067\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0065 - cross entropy: 0.0065 - Brier score: 9.8212e-04 - tp: 149.0000 - fp: 23.0000 - tn: 181929.0000 - fn: 175.0000 - accuracy: 0.9989 - precision: 0.8663 - recall: 0.4599 - auc: 0.8710 - prc: 0.5592 - val_loss: 0.0038 - val_cross entropy: 0.0038 - val_Brier score: 6.9702e-04 - val_tp: 51.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 29.0000 - val_accuracy: 0.9991 - val_precision: 0.8226 - val_recall: 0.6375 - val_auc: 0.9373 - val_prc: 0.7246\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0061 - cross entropy: 0.0061 - Brier score: 9.4595e-04 - tp: 153.0000 - fp: 31.0000 - tn: 181921.0000 - fn: 171.0000 - accuracy: 0.9989 - precision: 0.8315 - recall: 0.4722 - auc: 0.8734 - prc: 0.6059 - val_loss: 0.0037 - val_cross entropy: 0.0037 - val_Brier score: 6.1448e-04 - val_tp: 60.0000 - val_fp: 12.0000 - val_tn: 45477.0000 - val_fn: 20.0000 - val_accuracy: 0.9993 - val_precision: 0.8333 - val_recall: 0.7500 - val_auc: 0.9373 - val_prc: 0.7434\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0054 - cross entropy: 0.0054 - Brier score: 8.1030e-04 - tp: 184.0000 - fp: 28.0000 - tn: 181924.0000 - fn: 140.0000 - accuracy: 0.9991 - precision: 0.8679 - recall: 0.5679 - auc: 0.9163 - prc: 0.6651 - val_loss: 0.0036 - val_cross entropy: 0.0036 - val_Brier score: 5.7560e-04 - val_tp: 63.0000 - val_fp: 12.0000 - val_tn: 45477.0000 - val_fn: 17.0000 - val_accuracy: 0.9994 - val_precision: 0.8400 - val_recall: 0.7875 - val_auc: 0.9373 - val_prc: 0.7205\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0052 - cross entropy: 0.0052 - Brier score: 8.5411e-04 - tp: 172.0000 - fp: 28.0000 - tn: 181924.0000 - fn: 152.0000 - accuracy: 0.9990 - precision: 0.8600 - recall: 0.5309 - auc: 0.9119 - prc: 0.6671 - val_loss: 0.0036 - val_cross entropy: 0.0036 - val_Brier score: 5.4080e-04 - val_tp: 67.0000 - val_fp: 12.0000 - val_tn: 45477.0000 - val_fn: 13.0000 - val_accuracy: 0.9995 - val_precision: 0.8481 - val_recall: 0.8375 - val_auc: 0.9498 - val_prc: 0.7540\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0053 - cross entropy: 0.0053 - Brier score: 8.1137e-04 - tp: 193.0000 - fp: 34.0000 - tn: 181918.0000 - fn: 131.0000 - accuracy: 0.9991 - precision: 0.8502 - recall: 0.5957 - auc: 0.9104 - prc: 0.6647 - val_loss: 0.0035 - val_cross entropy: 0.0035 - val_Brier score: 5.3436e-04 - val_tp: 67.0000 - val_fp: 12.0000 - val_tn: 45477.0000 - val_fn: 13.0000 - val_accuracy: 0.9995 - val_precision: 0.8481 - val_recall: 0.8375 - val_auc: 0.9498 - val_prc: 0.7579\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.0047 - cross entropy: 0.0047 - Brier score: 7.3675e-04 - tp: 197.0000 - fp: 25.0000 - tn: 181927.0000 - fn: 127.0000 - accuracy: 0.9992 - precision: 0.8874 - recall: 0.6080 - auc: 0.9124 - prc: 0.7044 - val_loss: 0.0034 - val_cross entropy: 0.0034 - val_Brier score: 5.2871e-04 - val_tp: 67.0000 - val_fp: 12.0000 - val_tn: 45477.0000 - val_fn: 13.0000 - val_accuracy: 0.9995 - val_precision: 0.8481 - val_recall: 0.8375 - val_auc: 0.9497 - val_prc: 0.7564\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0047 - cross entropy: 0.0047 - Brier score: 7.9086e-04 - tp: 193.0000 - fp: 38.0000 - tn: 181914.0000 - fn: 131.0000 - accuracy: 0.9991 - precision: 0.8355 - recall: 0.5957 - auc: 0.9171 - prc: 0.6757 - val_loss: 0.0031 - val_cross entropy: 0.0031 - val_Brier score: 5.3588e-04 - val_tp: 67.0000 - val_fp: 12.0000 - val_tn: 45477.0000 - val_fn: 13.0000 - val_accuracy: 0.9995 - val_precision: 0.8481 - val_recall: 0.8375 - val_auc: 0.9498 - val_prc: 0.8007\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0048 - cross entropy: 0.0048 - Brier score: 8.2775e-04 - tp: 186.0000 - fp: 32.0000 - tn: 181920.0000 - fn: 138.0000 - accuracy: 0.9991 - precision: 0.8532 - recall: 0.5741 - auc: 0.9233 - prc: 0.6821 - val_loss: 0.0031 - val_cross entropy: 0.0031 - val_Brier score: 5.2442e-04 - val_tp: 67.0000 - val_fp: 12.0000 - val_tn: 45477.0000 - val_fn: 13.0000 - val_accuracy: 0.9995 - val_precision: 0.8481 - val_recall: 0.8375 - val_auc: 0.9560 - val_prc: 0.8172\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0044 - cross entropy: 0.0044 - Brier score: 7.5607e-04 - tp: 197.0000 - fp: 32.0000 - tn: 181920.0000 - fn: 127.0000 - accuracy: 0.9991 - precision: 0.8603 - recall: 0.6080 - auc: 0.9217 - prc: 0.7031 - val_loss: 0.0029 - val_cross entropy: 0.0029 - val_Brier score: 5.1919e-04 - val_tp: 67.0000 - val_fp: 12.0000 - val_tn: 45477.0000 - val_fn: 13.0000 - val_accuracy: 0.9995 - val_precision: 0.8481 - val_recall: 0.8375 - val_auc: 0.9560 - val_prc: 0.8238\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0042 - cross entropy: 0.0042 - Brier score: 7.2500e-04 - tp: 199.0000 - fp: 28.0000 - tn: 181924.0000 - fn: 125.0000 - accuracy: 0.9992 - precision: 0.8767 - recall: 0.6142 - auc: 0.9280 - prc: 0.7242 - val_loss: 0.0028 - val_cross entropy: 0.0028 - val_Brier score: 5.1020e-04 - val_tp: 67.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 13.0000 - val_accuracy: 0.9995 - val_precision: 0.8590 - val_recall: 0.8375 - val_auc: 0.9560 - val_prc: 0.8325\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0041 - cross entropy: 0.0041 - Brier score: 7.2585e-04 - tp: 197.0000 - fp: 29.0000 - tn: 181923.0000 - fn: 127.0000 - accuracy: 0.9991 - precision: 0.8717 - recall: 0.6080 - auc: 0.9280 - prc: 0.7195 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 5.0042e-04 - val_tp: 68.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 12.0000 - val_accuracy: 0.9995 - val_precision: 0.8608 - val_recall: 0.8500 - val_auc: 0.9560 - val_prc: 0.8342\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0043 - cross entropy: 0.0043 - Brier score: 7.3986e-04 - tp: 200.0000 - fp: 28.0000 - tn: 181924.0000 - fn: 124.0000 - accuracy: 0.9992 - precision: 0.8772 - recall: 0.6173 - auc: 0.9203 - prc: 0.7127 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.9611e-04 - val_tp: 68.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 12.0000 - val_accuracy: 0.9995 - val_precision: 0.8608 - val_recall: 0.8500 - val_auc: 0.9560 - val_prc: 0.8335\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0043 - cross entropy: 0.0043 - Brier score: 7.2351e-04 - tp: 204.0000 - fp: 28.0000 - tn: 181924.0000 - fn: 120.0000 - accuracy: 0.9992 - precision: 0.8793 - recall: 0.6296 - auc: 0.9157 - prc: 0.7096 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.9317e-04 - val_tp: 68.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 12.0000 - val_accuracy: 0.9995 - val_precision: 0.8608 - val_recall: 0.8500 - val_auc: 0.9560 - val_prc: 0.8399\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0040 - cross entropy: 0.0040 - Brier score: 7.4380e-04 - tp: 192.0000 - fp: 28.0000 - tn: 181924.0000 - fn: 132.0000 - accuracy: 0.9991 - precision: 0.8727 - recall: 0.5926 - auc: 0.9328 - prc: 0.7450 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.8507e-04 - val_tp: 68.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 12.0000 - val_accuracy: 0.9995 - val_precision: 0.8608 - val_recall: 0.8500 - val_auc: 0.9560 - val_prc: 0.8435\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0038 - cross entropy: 0.0038 - Brier score: 6.8227e-04 - tp: 209.0000 - fp: 27.0000 - tn: 181925.0000 - fn: 115.0000 - accuracy: 0.9992 - precision: 0.8856 - recall: 0.6451 - auc: 0.9420 - prc: 0.7568 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.8149e-04 - val_tp: 68.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 12.0000 - val_accuracy: 0.9995 - val_precision: 0.8608 - val_recall: 0.8500 - val_auc: 0.9560 - val_prc: 0.8439\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0042 - cross entropy: 0.0042 - Brier score: 7.9943e-04 - tp: 184.0000 - fp: 30.0000 - tn: 181922.0000 - fn: 140.0000 - accuracy: 0.9991 - precision: 0.8598 - recall: 0.5679 - auc: 0.9280 - prc: 0.7106 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.7988e-04 - val_tp: 68.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 12.0000 - val_accuracy: 0.9995 - val_precision: 0.8608 - val_recall: 0.8500 - val_auc: 0.9560 - val_prc: 0.8440\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0041 - cross entropy: 0.0041 - Brier score: 7.4343e-04 - tp: 194.0000 - fp: 30.0000 - tn: 181922.0000 - fn: 130.0000 - accuracy: 0.9991 - precision: 0.8661 - recall: 0.5988 - auc: 0.9311 - prc: 0.7182 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.7884e-04 - val_tp: 68.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 12.0000 - val_accuracy: 0.9995 - val_precision: 0.8608 - val_recall: 0.8500 - val_auc: 0.9560 - val_prc: 0.8473\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0038 - cross entropy: 0.0038 - Brier score: 7.0768e-04 - tp: 201.0000 - fp: 29.0000 - tn: 181923.0000 - fn: 123.0000 - accuracy: 0.9992 - precision: 0.8739 - recall: 0.6204 - auc: 0.9343 - prc: 0.7534 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.7887e-04 - val_tp: 68.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 12.0000 - val_accuracy: 0.9995 - val_precision: 0.8608 - val_recall: 0.8500 - val_auc: 0.9560 - val_prc: 0.8470\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0043 - cross entropy: 0.0043 - Brier score: 7.7086e-04 - tp: 201.0000 - fp: 35.0000 - tn: 181917.0000 - fn: 123.0000 - accuracy: 0.9991 - precision: 0.8517 - recall: 0.6204 - auc: 0.9250 - prc: 0.7075 - val_loss: 0.0026 - val_cross entropy: 0.0026 - val_Brier score: 4.8335e-04 - val_tp: 64.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 16.0000 - val_accuracy: 0.9994 - val_precision: 0.8533 - val_recall: 0.8000 - val_auc: 0.9560 - val_prc: 0.8545\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0039 - cross entropy: 0.0039 - Brier score: 7.0493e-04 - tp: 208.0000 - fp: 29.0000 - tn: 181923.0000 - fn: 116.0000 - accuracy: 0.9992 - precision: 0.8776 - recall: 0.6420 - auc: 0.9312 - prc: 0.7440 - val_loss: 0.0026 - val_cross entropy: 0.0026 - val_Brier score: 4.8735e-04 - val_tp: 64.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 16.0000 - val_accuracy: 0.9994 - val_precision: 0.8533 - val_recall: 0.8000 - val_auc: 0.9560 - val_prc: 0.8552\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0037 - cross entropy: 0.0037 - Brier score: 6.6915e-04 - tp: 210.0000 - fp: 23.0000 - tn: 181929.0000 - fn: 114.0000 - accuracy: 0.9992 - precision: 0.9013 - recall: 0.6481 - auc: 0.9405 - prc: 0.7590 - val_loss: 0.0026 - val_cross entropy: 0.0026 - val_Brier score: 4.7675e-04 - val_tp: 68.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 12.0000 - val_accuracy: 0.9995 - val_precision: 0.8608 - val_recall: 0.8500 - val_auc: 0.9560 - val_prc: 0.8515\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0038 - cross entropy: 0.0038 - Brier score: 7.0353e-04 - tp: 212.0000 - fp: 39.0000 - tn: 181913.0000 - fn: 112.0000 - accuracy: 0.9992 - precision: 0.8446 - recall: 0.6543 - auc: 0.9375 - prc: 0.7492 - val_loss: 0.0026 - val_cross entropy: 0.0026 - val_Brier score: 4.7722e-04 - val_tp: 67.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 13.0000 - val_accuracy: 0.9995 - val_precision: 0.8590 - val_recall: 0.8375 - val_auc: 0.9560 - val_prc: 0.8516\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0036 - cross entropy: 0.0036 - Brier score: 6.7028e-04 - tp: 206.0000 - fp: 26.0000 - tn: 181926.0000 - fn: 118.0000 - accuracy: 0.9992 - precision: 0.8879 - recall: 0.6358 - auc: 0.9375 - prc: 0.7605 - val_loss: 0.0026 - val_cross entropy: 0.0026 - val_Brier score: 4.7876e-04 - val_tp: 66.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 14.0000 - val_accuracy: 0.9995 - val_precision: 0.8571 - val_recall: 0.8250 - val_auc: 0.9560 - val_prc: 0.8549\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0040 - cross entropy: 0.0040 - Brier score: 7.4745e-04 - tp: 195.0000 - fp: 28.0000 - tn: 181924.0000 - fn: 129.0000 - accuracy: 0.9991 - precision: 0.8744 - recall: 0.6019 - auc: 0.9297 - prc: 0.7327 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.7676e-04 - val_tp: 68.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 12.0000 - val_accuracy: 0.9995 - val_precision: 0.8608 - val_recall: 0.8500 - val_auc: 0.9560 - val_prc: 0.8501\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0038 - cross entropy: 0.0038 - Brier score: 7.0114e-04 - tp: 201.0000 - fp: 26.0000 - tn: 181926.0000 - fn: 123.0000 - accuracy: 0.9992 - precision: 0.8855 - recall: 0.6204 - auc: 0.9297 - prc: 0.7316 - val_loss: 0.0026 - val_cross entropy: 0.0026 - val_Brier score: 4.7980e-04 - val_tp: 66.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 14.0000 - val_accuracy: 0.9995 - val_precision: 0.8571 - val_recall: 0.8250 - val_auc: 0.9560 - val_prc: 0.8568\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0036 - cross entropy: 0.0036 - Brier score: 6.6086e-04 - tp: 218.0000 - fp: 36.0000 - tn: 181916.0000 - fn: 106.0000 - accuracy: 0.9992 - precision: 0.8583 - recall: 0.6728 - auc: 0.9406 - prc: 0.7728 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.7783e-04 - val_tp: 68.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 12.0000 - val_accuracy: 0.9995 - val_precision: 0.8608 - val_recall: 0.8500 - val_auc: 0.9560 - val_prc: 0.8521\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0037 - cross entropy: 0.0037 - Brier score: 6.9430e-04 - tp: 205.0000 - fp: 27.0000 - tn: 181925.0000 - fn: 119.0000 - accuracy: 0.9992 - precision: 0.8836 - recall: 0.6327 - auc: 0.9390 - prc: 0.7675 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.7868e-04 - val_tp: 67.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 13.0000 - val_accuracy: 0.9995 - val_precision: 0.8590 - val_recall: 0.8375 - val_auc: 0.9560 - val_prc: 0.8526\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0036 - cross entropy: 0.0036 - Brier score: 6.7774e-04 - tp: 207.0000 - fp: 30.0000 - tn: 181922.0000 - fn: 117.0000 - accuracy: 0.9992 - precision: 0.8734 - recall: 0.6389 - auc: 0.9360 - prc: 0.7665 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.8465e-04 - val_tp: 64.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 16.0000 - val_accuracy: 0.9994 - val_precision: 0.8533 - val_recall: 0.8000 - val_auc: 0.9560 - val_prc: 0.8573\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0037 - cross entropy: 0.0037 - Brier score: 6.5368e-04 - tp: 213.0000 - fp: 26.0000 - tn: 181926.0000 - fn: 111.0000 - accuracy: 0.9992 - precision: 0.8912 - recall: 0.6574 - auc: 0.9313 - prc: 0.7525 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.7826e-04 - val_tp: 68.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 12.0000 - val_accuracy: 0.9995 - val_precision: 0.8608 - val_recall: 0.8500 - val_auc: 0.9560 - val_prc: 0.8560\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0035 - cross entropy: 0.0035 - Brier score: 6.4433e-04 - tp: 223.0000 - fp: 32.0000 - tn: 181920.0000 - fn: 101.0000 - accuracy: 0.9993 - precision: 0.8745 - recall: 0.6883 - auc: 0.9437 - prc: 0.7771 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.8466e-04 - val_tp: 64.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 16.0000 - val_accuracy: 0.9994 - val_precision: 0.8533 - val_recall: 0.8000 - val_auc: 0.9560 - val_prc: 0.8551\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0037 - cross entropy: 0.0037 - Brier score: 6.9070e-04 - tp: 205.0000 - fp: 27.0000 - tn: 181925.0000 - fn: 119.0000 - accuracy: 0.9992 - precision: 0.8836 - recall: 0.6327 - auc: 0.9298 - prc: 0.7471 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.8274e-04 - val_tp: 66.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 14.0000 - val_accuracy: 0.9995 - val_precision: 0.8571 - val_recall: 0.8250 - val_auc: 0.9560 - val_prc: 0.8576\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0037 - cross entropy: 0.0037 - Brier score: 6.8638e-04 - tp: 207.0000 - fp: 32.0000 - tn: 181920.0000 - fn: 117.0000 - accuracy: 0.9992 - precision: 0.8661 - recall: 0.6389 - auc: 0.9345 - prc: 0.7542 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.9248e-04 - val_tp: 62.0000 - val_fp: 10.0000 - val_tn: 45479.0000 - val_fn: 18.0000 - val_accuracy: 0.9994 - val_precision: 0.8611 - val_recall: 0.7750 - val_auc: 0.9560 - val_prc: 0.8573\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0036 - cross entropy: 0.0036 - Brier score: 6.8737e-04 - tp: 205.0000 - fp: 22.0000 - tn: 181930.0000 - fn: 119.0000 - accuracy: 0.9992 - precision: 0.9031 - recall: 0.6327 - auc: 0.9344 - prc: 0.7570 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.8493e-04 - val_tp: 65.0000 - val_fp: 12.0000 - val_tn: 45477.0000 - val_fn: 15.0000 - val_accuracy: 0.9994 - val_precision: 0.8442 - val_recall: 0.8125 - val_auc: 0.9560 - val_prc: 0.8544\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0035 - cross entropy: 0.0035 - Brier score: 6.4538e-04 - tp: 213.0000 - fp: 26.0000 - tn: 181926.0000 - fn: 111.0000 - accuracy: 0.9992 - precision: 0.8912 - recall: 0.6574 - auc: 0.9375 - prc: 0.7697 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.9744e-04 - val_tp: 60.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 20.0000 - val_accuracy: 0.9993 - val_precision: 0.8451 - val_recall: 0.7500 - val_auc: 0.9560 - val_prc: 0.8589\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0035 - cross entropy: 0.0035 - Brier score: 6.5299e-04 - tp: 212.0000 - fp: 28.0000 - tn: 181924.0000 - fn: 112.0000 - accuracy: 0.9992 - precision: 0.8833 - recall: 0.6543 - auc: 0.9436 - prc: 0.7673 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.8188e-04 - val_tp: 65.0000 - val_fp: 12.0000 - val_tn: 45477.0000 - val_fn: 15.0000 - val_accuracy: 0.9994 - val_precision: 0.8442 - val_recall: 0.8125 - val_auc: 0.9560 - val_prc: 0.8557\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0037 - cross entropy: 0.0037 - Brier score: 7.3177e-04 - tp: 201.0000 - fp: 34.0000 - tn: 181918.0000 - fn: 123.0000 - accuracy: 0.9991 - precision: 0.8553 - recall: 0.6204 - auc: 0.9328 - prc: 0.7478 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.8951e-04 - val_tp: 62.0000 - val_fp: 12.0000 - val_tn: 45477.0000 - val_fn: 18.0000 - val_accuracy: 0.9993 - val_precision: 0.8378 - val_recall: 0.7750 - val_auc: 0.9560 - val_prc: 0.8590\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0033 - cross entropy: 0.0033 - Brier score: 6.1811e-04 - tp: 224.0000 - fp: 27.0000 - tn: 181925.0000 - fn: 100.0000 - accuracy: 0.9993 - precision: 0.8924 - recall: 0.6914 - auc: 0.9422 - prc: 0.7940 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.8988e-04 - val_tp: 64.0000 - val_fp: 12.0000 - val_tn: 45477.0000 - val_fn: 16.0000 - val_accuracy: 0.9994 - val_precision: 0.8421 - val_recall: 0.8000 - val_auc: 0.9560 - val_prc: 0.8546\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0035 - cross entropy: 0.0035 - Brier score: 6.5865e-04 - tp: 211.0000 - fp: 27.0000 - tn: 181925.0000 - fn: 113.0000 - accuracy: 0.9992 - precision: 0.8866 - recall: 0.6512 - auc: 0.9299 - prc: 0.7613 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.9682e-04 - val_tp: 60.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 20.0000 - val_accuracy: 0.9993 - val_precision: 0.8451 - val_recall: 0.7500 - val_auc: 0.9560 - val_prc: 0.8578\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0035 - cross entropy: 0.0035 - Brier score: 6.8332e-04 - tp: 206.0000 - fp: 28.0000 - tn: 181924.0000 - fn: 118.0000 - accuracy: 0.9992 - precision: 0.8803 - recall: 0.6358 - auc: 0.9375 - prc: 0.7673 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.9293e-04 - val_tp: 61.0000 - val_fp: 11.0000 - val_tn: 45478.0000 - val_fn: 19.0000 - val_accuracy: 0.9993 - val_precision: 0.8472 - val_recall: 0.7625 - val_auc: 0.9560 - val_prc: 0.8588\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0034 - cross entropy: 0.0034 - Brier score: 6.1576e-04 - tp: 217.0000 - fp: 21.0000 - tn: 181931.0000 - fn: 107.0000 - accuracy: 0.9993 - precision: 0.9118 - recall: 0.6698 - auc: 0.9391 - prc: 0.7796 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.8166e-04 - val_tp: 66.0000 - val_fp: 12.0000 - val_tn: 45477.0000 - val_fn: 14.0000 - val_accuracy: 0.9994 - val_precision: 0.8462 - val_recall: 0.8250 - val_auc: 0.9560 - val_prc: 0.8568\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0034 - cross entropy: 0.0034 - Brier score: 6.2516e-04 - tp: 219.0000 - fp: 26.0000 - tn: 181926.0000 - fn: 105.0000 - accuracy: 0.9993 - precision: 0.8939 - recall: 0.6759 - auc: 0.9345 - prc: 0.7805 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.7956e-04 - val_tp: 66.0000 - val_fp: 12.0000 - val_tn: 45477.0000 - val_fn: 14.0000 - val_accuracy: 0.9994 - val_precision: 0.8462 - val_recall: 0.8250 - val_auc: 0.9560 - val_prc: 0.8556\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0036 - cross entropy: 0.0036 - Brier score: 6.6786e-04 - tp: 213.0000 - fp: 26.0000 - tn: 181926.0000 - fn: 111.0000 - accuracy: 0.9992 - precision: 0.8912 - recall: 0.6574 - auc: 0.9360 - prc: 0.7589 - val_loss: 0.0028 - val_cross entropy: 0.0028 - val_Brier score: 4.8066e-04 - val_tp: 67.0000 - val_fp: 12.0000 - val_tn: 45477.0000 - val_fn: 13.0000 - val_accuracy: 0.9995 - val_precision: 0.8481 - val_recall: 0.8375 - val_auc: 0.9560 - val_prc: 0.8571\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0034 - cross entropy: 0.0034 - Brier score: 6.3402e-04 - tp: 217.0000 - fp: 27.0000 - tn: 181925.0000 - fn: 107.0000 - accuracy: 0.9993 - precision: 0.8893 - recall: 0.6698 - auc: 0.9453 - prc: 0.7789 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 4.8686e-04 - val_tp: 65.0000 - val_fp: 12.0000 - val_tn: 45477.0000 - val_fn: 15.0000 - val_accuracy: 0.9994 - val_precision: 0.8442 - val_recall: 0.8125 - val_auc: 0.9560 - val_prc: 0.8588\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0035 - cross entropy: 0.0035 - Brier score: 6.5749e-04 - tp: 211.0000 - fp: 26.0000 - tn: 181926.0000 - fn: 113.0000 - accuracy: 0.9992 - precision: 0.8903 - recall: 0.6512 - auc: 0.9376 - prc: 0.7786 - val_loss: 0.0028 - val_cross entropy: 0.0028 - val_Brier score: 4.8337e-04 - val_tp: 66.0000 - val_fp: 12.0000 - val_tn: 45477.0000 - val_fn: 14.0000 - val_accuracy: 0.9994 - val_precision: 0.8462 - val_recall: 0.8250 - val_auc: 0.9560 - val_prc: 0.8565\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0035 - cross entropy: 0.0035 - Brier score: 6.4873e-04 - tp: 220.0000 - fp: 34.0000 - tn: 181918.0000 - fn: 104.0000 - accuracy: 0.9992 - precision: 0.8661 - recall: 0.6790 - auc: 0.9329 - prc: 0.7674 - val_loss: 0.0027 - val_cross entropy: 0.0027 - val_Brier score: 5.0112e-04 - val_tp: 60.0000 - val_fp: 10.0000 - val_tn: 45479.0000 - val_fn: 20.0000 - val_accuracy: 0.9993 - val_precision: 0.8571 - val_recall: 0.7500 - val_auc: 0.9560 - val_prc: 0.8570\n",
      "Epoch 48/100\n",
      "81/90 [==========================>...] - ETA: 0s - loss: 0.0034 - cross entropy: 0.0034 - Brier score: 6.2708e-04 - tp: 199.0000 - fp: 20.0000 - tn: 165570.0000 - fn: 99.0000 - accuracy: 0.9993 - precision: 0.9087 - recall: 0.6678 - auc: 0.9322 - prc: 0.7816Restoring model weights from the end of the best epoch: 38.\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0033 - cross entropy: 0.0033 - Brier score: 6.0584e-04 - tp: 218.0000 - fp: 21.0000 - tn: 181931.0000 - fn: 106.0000 - accuracy: 0.9993 - precision: 0.9121 - recall: 0.6728 - auc: 0.9330 - prc: 0.7874 - val_loss: 0.0028 - val_cross entropy: 0.0028 - val_Brier score: 4.8667e-04 - val_tp: 66.0000 - val_fp: 12.0000 - val_tn: 45477.0000 - val_fn: 14.0000 - val_accuracy: 0.9994 - val_precision: 0.8462 - val_recall: 0.8250 - val_auc: 0.9560 - val_prc: 0.8569\n",
      "Epoch 48: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "model.load_weights(initial_weights)\n",
    "baseline_history = model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSaDBYU9xtP6"
   },
   "source": [
    "### Check training history\n",
    "\n",
    "In this section, you will produce plots of your model's accuracy and loss on the training and validation set. These are useful to check for overfitting, which you can learn more about in the [Overfit and underfit](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit) tutorial.\n",
    "\n",
    "Additionally, you can produce these plots for any of the metrics you created above. False negatives are included as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:13.366249Z",
     "iopub.status.busy": "2023-07-27T04:53:13.365951Z",
     "iopub.status.idle": "2023-07-27T04:53:13.372128Z",
     "shell.execute_reply": "2023-07-27T04:53:13.371345Z"
    },
    "id": "WTSkhT1jyGu6"
   },
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'prc', 'precision', 'recall']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:13.375112Z",
     "iopub.status.busy": "2023-07-27T04:53:13.374863Z",
     "iopub.status.idle": "2023-07-27T04:53:13.961103Z",
     "shell.execute_reply": "2023-07-27T04:53:13.960412Z"
    },
    "id": "u6LReDsqlZlk"
   },
   "outputs": [],
   "source": [
    "plot_metrics(baseline_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCa4iWo6WDKR"
   },
   "source": [
    "Note: That the validation curve generally performs better than the training curve. This is mainly caused by the fact that the dropout layer is not active when evaluating the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJC1booryouo"
   },
   "source": [
    "### Evaluate metrics\n",
    "\n",
    "You can use a [confusion matrix](https://developers.google.com/machine-learning/glossary/#confusion_matrix) to summarize the actual vs. predicted labels, where the X axis is the predicted label and the Y axis is the actual label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:13.965085Z",
     "iopub.status.busy": "2023-07-27T04:53:13.964845Z",
     "iopub.status.idle": "2023-07-27T04:53:14.384573Z",
     "shell.execute_reply": "2023-07-27T04:53:14.383891Z"
    },
    "id": "aNS796IJKrev"
   },
   "outputs": [],
   "source": [
    "train_predictions_baseline = model.predict(train_features, batch_size=BATCH_SIZE)\n",
    "test_predictions_baseline = model.predict(test_features, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:14.388308Z",
     "iopub.status.busy": "2023-07-27T04:53:14.387667Z",
     "iopub.status.idle": "2023-07-27T04:53:14.393021Z",
     "shell.execute_reply": "2023-07-27T04:53:14.392448Z"
    },
    "id": "MVWBGfADwbWI"
   },
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, threshold=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > threshold)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(threshold))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
    "  print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "  print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
    "  print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
    "  print('Total Fraudulent Transactions: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOTjD5Z5Wp1U"
   },
   "source": [
    "Evaluate your model on the test dataset and display the results for the metrics you created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:14.396287Z",
     "iopub.status.busy": "2023-07-27T04:53:14.395818Z",
     "iopub.status.idle": "2023-07-27T04:53:14.734769Z",
     "shell.execute_reply": "2023-07-27T04:53:14.734137Z"
    },
    "id": "poh_hZngt2_9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.0032950816676020622\n",
      "cross entropy :  0.0032950816676020622\n",
      "Brier score :  0.0005497767124325037\n",
      "tp :  65.0\n",
      "fp :  12.0\n",
      "tn :  56862.0\n",
      "fn :  23.0\n",
      "accuracy :  0.9993855357170105\n",
      "precision :  0.8441558480262756\n",
      "recall :  0.7386363744735718\n",
      "auc :  0.9086859226226807\n",
      "prc :  0.7423760294914246\n",
      "\n",
      "Legitimate Transactions Detected (True Negatives):  56862\n",
      "Legitimate Transactions Incorrectly Detected (False Positives):  12\n",
      "Fraudulent Transactions Missed (False Negatives):  23\n",
      "Fraudulent Transactions Detected (True Positives):  65\n",
      "Total Fraudulent Transactions:  88\n"
     ]
    }
   ],
   "source": [
    "baseline_results = model.evaluate(test_features, test_labels,\n",
    "                                  batch_size=BATCH_SIZE, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(test_labels, test_predictions_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyZtSr1v6L4t"
   },
   "source": [
    "If the model had predicted everything perfectly (impossible with true randomness), this would be a [diagonal matrix](https://en.wikipedia.org/wiki/Diagonal_matrix) where values off the main diagonal, indicating incorrect predictions, would be zero. In this case, the matrix shows that you have relatively few false positives, meaning that there were relatively few legitimate transactions that were incorrectly flagged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-QpQsip_F2Q"
   },
   "source": [
    "### Changing the threshold\n",
    "\n",
    "The default threshold of $t=50\\%$ corresponds to equal costs of false negatives and false positives.\n",
    "In the case of fraud detection, however, you would likely associate higher costs to false negatives than to false positives.\n",
    "This trade off may be preferable because false negatives would allow fraudulent transactions to go through, whereas false positives may cause an email to be sent to a customer to ask them to verify their card activity.\n",
    "\n",
    "By decreasing the threshold, we attribute higher cost to false negatives, thereby increasing missed transactions at the price of more false positives.\n",
    "We test thresholds at 10% and at 1%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:14.738184Z",
     "iopub.status.busy": "2023-07-27T04:53:14.737593Z",
     "iopub.status.idle": "2023-07-27T04:53:15.088686Z",
     "shell.execute_reply": "2023-07-27T04:53:15.088149Z"
    },
    "id": "52bd793e04bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legitimate Transactions Detected (True Negatives):  56855\n",
      "Legitimate Transactions Incorrectly Detected (False Positives):  19\n",
      "Fraudulent Transactions Missed (False Negatives):  20\n",
      "Fraudulent Transactions Detected (True Positives):  68\n",
      "Total Fraudulent Transactions:  88\n",
      "Legitimate Transactions Detected (True Negatives):  56776\n",
      "Legitimate Transactions Incorrectly Detected (False Positives):  98\n",
      "Fraudulent Transactions Missed (False Negatives):  17\n",
      "Fraudulent Transactions Detected (True Positives):  71\n",
      "Total Fraudulent Transactions:  88\n"
     ]
    }
   ],
   "source": [
    "plot_cm(test_labels, test_predictions_baseline, threshold=0.1)\n",
    "plot_cm(test_labels, test_predictions_baseline, threshold=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-QpQsip_F2Q"
   },
   "source": [
    "### Plot the ROC\n",
    "\n",
    "Now plot the [ROC](https://developers.google.com/machine-learning/glossary#ROC). This plot is useful because it shows, at a glance, the range of performance the model can reach by tuning the output threshold over its full range (0 to 1). So each point corresponds to a single value of the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:15.091727Z",
     "iopub.status.busy": "2023-07-27T04:53:15.091501Z",
     "iopub.status.idle": "2023-07-27T04:53:15.095958Z",
     "shell.execute_reply": "2023-07-27T04:53:15.095356Z"
    },
    "id": "lhaxsLSvANF9"
   },
   "outputs": [],
   "source": [
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "  fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n",
    "\n",
    "  plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
    "  plt.xlabel('False positives [%]')\n",
    "  plt.ylabel('True positives [%]')\n",
    "  plt.xlim([-0.5,20])\n",
    "  plt.ylim([80,100.5])\n",
    "  plt.grid(True)\n",
    "  ax = plt.gca()\n",
    "  ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:15.099025Z",
     "iopub.status.busy": "2023-07-27T04:53:15.098453Z",
     "iopub.status.idle": "2023-07-27T04:53:15.357356Z",
     "shell.execute_reply": "2023-07-27T04:53:15.356637Z"
    },
    "id": "DfHHspttKJE0"
   },
   "outputs": [],
   "source": [
    "plot_roc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\n",
    "plot_roc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5twGRLfNwmO"
   },
   "source": [
    "### Plot the PRC\n",
    "\n",
    "Now plot the [AUPRC](https://developers.google.com/machine-learning/glossary?hl=en#PR_AUC). Area under the interpolated precision-recall curve, obtained by plotting (recall, precision) points for different values of the classification threshold. Depending on how it's calculated, PR AUC may be equivalent to the average precision of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:15.361481Z",
     "iopub.status.busy": "2023-07-27T04:53:15.360847Z",
     "iopub.status.idle": "2023-07-27T04:53:15.365164Z",
     "shell.execute_reply": "2023-07-27T04:53:15.364513Z"
    },
    "id": "XV6JSlFGEqGI"
   },
   "outputs": [],
   "source": [
    "def plot_prc(name, labels, predictions, **kwargs):\n",
    "    precision, recall, _ = sklearn.metrics.precision_recall_curve(labels, predictions)\n",
    "\n",
    "    plt.plot(precision, recall, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('Precision')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:15.368267Z",
     "iopub.status.busy": "2023-07-27T04:53:15.367836Z",
     "iopub.status.idle": "2023-07-27T04:53:15.620227Z",
     "shell.execute_reply": "2023-07-27T04:53:15.619585Z"
    },
    "id": "FdQs_PcqEsiL"
   },
   "outputs": [],
   "source": [
    "plot_prc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\n",
    "plot_prc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpdsFyp64DhY"
   },
   "source": [
    "It looks like the precision is relatively high, but the recall and the area under the ROC curve (AUC) aren't as high as you might like. Classifiers often face challenges when trying to maximize both precision and recall, which is especially true when working with imbalanced datasets. It is important to consider the costs of different types of errors in the context of the problem you care about. In this example, a false negative (a fraudulent transaction is missed) may have a financial cost, while a false positive (a transaction is incorrectly flagged as fraudulent) may decrease user happiness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cveQoiMyGQCo"
   },
   "source": [
    "## Class weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePGp6GUE1WfH"
   },
   "source": [
    "### Calculate class weights\n",
    "\n",
    "The goal is to identify fraudulent transactions, but you don't have very many of those positive samples to work with, so you would want to have the classifier heavily weight the few examples that are available. You can do this by passing Keras weights for each class through a parameter. These will cause the model to \"pay more attention\" to examples from an under-represented class. Note, however, that this does not increase in any way the amount of information of your dataset. In the end, using class weights is more or less equivalent to changing the output bias or to changing the threshold. Let's see how it works out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:15.623984Z",
     "iopub.status.busy": "2023-07-27T04:53:15.623400Z",
     "iopub.status.idle": "2023-07-27T04:53:15.627729Z",
     "shell.execute_reply": "2023-07-27T04:53:15.627129Z"
    },
    "id": "qjGWErngGny7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 0.50\n",
      "Weight for class 1: 289.44\n"
     ]
    }
   ],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mk1OOE2ZSHzy"
   },
   "source": [
    "### Train a model with class weights\n",
    "\n",
    "Now try re-training and evaluating the model with class weights to see how that affects the predictions.\n",
    "\n",
    "Note: Using `class_weights` changes the range of the loss. This may affect the stability of the training depending on the optimizer. Optimizers whose step size is dependent on the magnitude of the gradient, like `tf.keras.optimizers.SGD`, may fail. The optimizer used here, `tf.keras.optimizers.Adam`, is unaffected by the scaling change. Also note that because of the weighting, the total losses are not comparable between the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:15.630589Z",
     "iopub.status.busy": "2023-07-27T04:53:15.630333Z",
     "iopub.status.idle": "2023-07-27T04:53:23.316824Z",
     "shell.execute_reply": "2023-07-27T04:53:23.316003Z"
    },
    "id": "UJ589fn8ST3x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "90/90 [==============================] - 2s 9ms/step - loss: 3.0328 - cross entropy: 0.0111 - Brier score: 0.0014 - tp: 100.0000 - fp: 36.0000 - tn: 238790.0000 - fn: 312.0000 - accuracy: 0.9985 - precision: 0.7353 - recall: 0.2427 - auc: 0.7279 - prc: 0.2780 - val_loss: 0.0063 - val_cross entropy: 0.0063 - val_Brier score: 0.0011 - val_tp: 27.0000 - val_fp: 9.0000 - val_tn: 45480.0000 - val_fn: 53.0000 - val_accuracy: 0.9986 - val_precision: 0.7500 - val_recall: 0.3375 - val_auc: 0.9285 - val_prc: 0.5615\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 1.2485 - cross entropy: 0.0114 - Brier score: 0.0017 - tp: 143.0000 - fp: 165.0000 - tn: 181787.0000 - fn: 181.0000 - accuracy: 0.9981 - precision: 0.4643 - recall: 0.4414 - auc: 0.8742 - prc: 0.3852 - val_loss: 0.0067 - val_cross entropy: 0.0067 - val_Brier score: 6.4372e-04 - val_tp: 65.0000 - val_fp: 12.0000 - val_tn: 45477.0000 - val_fn: 15.0000 - val_accuracy: 0.9994 - val_precision: 0.8442 - val_recall: 0.8125 - val_auc: 0.9609 - val_prc: 0.6763\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.8480 - cross entropy: 0.0175 - Brier score: 0.0030 - tp: 204.0000 - fp: 528.0000 - tn: 181424.0000 - fn: 120.0000 - accuracy: 0.9964 - precision: 0.2787 - recall: 0.6296 - auc: 0.8934 - prc: 0.4937 - val_loss: 0.0098 - val_cross entropy: 0.0098 - val_Brier score: 8.5531e-04 - val_tp: 70.0000 - val_fp: 26.0000 - val_tn: 45463.0000 - val_fn: 10.0000 - val_accuracy: 0.9992 - val_precision: 0.7292 - val_recall: 0.8750 - val_auc: 0.9720 - val_prc: 0.7319\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6685 - cross entropy: 0.0278 - Brier score: 0.0054 - tp: 229.0000 - fp: 1063.0000 - tn: 180889.0000 - fn: 95.0000 - accuracy: 0.9936 - precision: 0.1772 - recall: 0.7068 - auc: 0.9102 - prc: 0.4659 - val_loss: 0.0153 - val_cross entropy: 0.0153 - val_Brier score: 0.0017 - val_tp: 71.0000 - val_fp: 63.0000 - val_tn: 45426.0000 - val_fn: 9.0000 - val_accuracy: 0.9984 - val_precision: 0.5299 - val_recall: 0.8875 - val_auc: 0.9704 - val_prc: 0.7368\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5298 - cross entropy: 0.0435 - Brier score: 0.0091 - tp: 243.0000 - fp: 1911.0000 - tn: 180041.0000 - fn: 81.0000 - accuracy: 0.9891 - precision: 0.1128 - recall: 0.7500 - auc: 0.9247 - prc: 0.3810 - val_loss: 0.0246 - val_cross entropy: 0.0246 - val_Brier score: 0.0040 - val_tp: 73.0000 - val_fp: 224.0000 - val_tn: 45265.0000 - val_fn: 7.0000 - val_accuracy: 0.9949 - val_precision: 0.2458 - val_recall: 0.9125 - val_auc: 0.9692 - val_prc: 0.6934\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4725 - cross entropy: 0.0608 - Brier score: 0.0130 - tp: 252.0000 - fp: 2734.0000 - tn: 179218.0000 - fn: 72.0000 - accuracy: 0.9846 - precision: 0.0844 - recall: 0.7778 - auc: 0.9323 - prc: 0.3179 - val_loss: 0.0385 - val_cross entropy: 0.0385 - val_Brier score: 0.0077 - val_tp: 73.0000 - val_fp: 475.0000 - val_tn: 45014.0000 - val_fn: 7.0000 - val_accuracy: 0.9894 - val_precision: 0.1332 - val_recall: 0.9125 - val_auc: 0.9681 - val_prc: 0.6886\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4045 - cross entropy: 0.0836 - Brier score: 0.0179 - tp: 263.0000 - fp: 3796.0000 - tn: 178156.0000 - fn: 61.0000 - accuracy: 0.9788 - precision: 0.0648 - recall: 0.8117 - auc: 0.9349 - prc: 0.2502 - val_loss: 0.0520 - val_cross entropy: 0.0520 - val_Brier score: 0.0109 - val_tp: 73.0000 - val_fp: 601.0000 - val_tn: 44888.0000 - val_fn: 7.0000 - val_accuracy: 0.9867 - val_precision: 0.1083 - val_recall: 0.9125 - val_auc: 0.9748 - val_prc: 0.6491\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3292 - cross entropy: 0.1061 - Brier score: 0.0225 - tp: 272.0000 - fp: 4811.0000 - tn: 177141.0000 - fn: 52.0000 - accuracy: 0.9733 - precision: 0.0535 - recall: 0.8395 - auc: 0.9556 - prc: 0.2100 - val_loss: 0.0657 - val_cross entropy: 0.0657 - val_Brier score: 0.0137 - val_tp: 73.0000 - val_fp: 725.0000 - val_tn: 44764.0000 - val_fn: 7.0000 - val_accuracy: 0.9839 - val_precision: 0.0915 - val_recall: 0.9125 - val_auc: 0.9734 - val_prc: 0.6159\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3985 - cross entropy: 0.1206 - Brier score: 0.0258 - tp: 272.0000 - fp: 5487.0000 - tn: 176465.0000 - fn: 52.0000 - accuracy: 0.9696 - precision: 0.0472 - recall: 0.8395 - auc: 0.9317 - prc: 0.1857 - val_loss: 0.0743 - val_cross entropy: 0.0743 - val_Brier score: 0.0154 - val_tp: 73.0000 - val_fp: 796.0000 - val_tn: 44693.0000 - val_fn: 7.0000 - val_accuracy: 0.9824 - val_precision: 0.0840 - val_recall: 0.9125 - val_auc: 0.9726 - val_prc: 0.5774\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3015 - cross entropy: 0.1290 - Brier score: 0.0277 - tp: 283.0000 - fp: 5973.0000 - tn: 175979.0000 - fn: 41.0000 - accuracy: 0.9670 - precision: 0.0452 - recall: 0.8735 - auc: 0.9537 - prc: 0.1914 - val_loss: 0.0797 - val_cross entropy: 0.0797 - val_Brier score: 0.0164 - val_tp: 73.0000 - val_fp: 851.0000 - val_tn: 44638.0000 - val_fn: 7.0000 - val_accuracy: 0.9812 - val_precision: 0.0790 - val_recall: 0.9125 - val_auc: 0.9739 - val_prc: 0.5721\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3496 - cross entropy: 0.1377 - Brier score: 0.0297 - tp: 273.0000 - fp: 6514.0000 - tn: 175438.0000 - fn: 51.0000 - accuracy: 0.9640 - precision: 0.0402 - recall: 0.8426 - auc: 0.9481 - prc: 0.1798 - val_loss: 0.0855 - val_cross entropy: 0.0855 - val_Brier score: 0.0175 - val_tp: 73.0000 - val_fp: 896.0000 - val_tn: 44593.0000 - val_fn: 7.0000 - val_accuracy: 0.9802 - val_precision: 0.0753 - val_recall: 0.9125 - val_auc: 0.9763 - val_prc: 0.5663\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2678 - cross entropy: 0.1374 - Brier score: 0.0299 - tp: 289.0000 - fp: 6526.0000 - tn: 175426.0000 - fn: 35.0000 - accuracy: 0.9640 - precision: 0.0424 - recall: 0.8920 - auc: 0.9610 - prc: 0.2020 - val_loss: 0.0829 - val_cross entropy: 0.0829 - val_Brier score: 0.0169 - val_tp: 73.0000 - val_fp: 859.0000 - val_tn: 44630.0000 - val_fn: 7.0000 - val_accuracy: 0.9810 - val_precision: 0.0783 - val_recall: 0.9125 - val_auc: 0.9763 - val_prc: 0.5616\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2608 - cross entropy: 0.1365 - Brier score: 0.0297 - tp: 289.0000 - fp: 6469.0000 - tn: 175483.0000 - fn: 35.0000 - accuracy: 0.9643 - precision: 0.0428 - recall: 0.8920 - auc: 0.9622 - prc: 0.1981 - val_loss: 0.0841 - val_cross entropy: 0.0841 - val_Brier score: 0.0171 - val_tp: 73.0000 - val_fp: 855.0000 - val_tn: 44634.0000 - val_fn: 7.0000 - val_accuracy: 0.9811 - val_precision: 0.0787 - val_recall: 0.9125 - val_auc: 0.9728 - val_prc: 0.5569\n",
      "Epoch 14/100\n",
      "80/90 [=========================>....] - ETA: 0s - loss: 0.2975 - cross entropy: 0.1387 - Brier score: 0.0302 - tp: 250.0000 - fp: 5902.0000 - tn: 157649.0000 - fn: 39.0000 - accuracy: 0.9637 - precision: 0.0406 - recall: 0.8651 - auc: 0.9530 - prc: 0.1953Restoring model weights from the end of the best epoch: 4.\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2798 - cross entropy: 0.1394 - Brier score: 0.0303 - tp: 284.0000 - fp: 6600.0000 - tn: 175352.0000 - fn: 40.0000 - accuracy: 0.9636 - precision: 0.0413 - recall: 0.8765 - auc: 0.9572 - prc: 0.2001 - val_loss: 0.0875 - val_cross entropy: 0.0875 - val_Brier score: 0.0177 - val_tp: 73.0000 - val_fp: 888.0000 - val_tn: 44601.0000 - val_fn: 7.0000 - val_accuracy: 0.9804 - val_precision: 0.0760 - val_recall: 0.9125 - val_auc: 0.9725 - val_prc: 0.5523\n",
      "Epoch 14: early stopping\n"
     ]
    }
   ],
   "source": [
    "weighted_model = make_model()\n",
    "weighted_model.load_weights(initial_weights)\n",
    "\n",
    "weighted_history = weighted_model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=(val_features, val_labels),\n",
    "    # The class weights go here\n",
    "    class_weight=class_weight) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0ynYRO0G3Lx"
   },
   "source": [
    "### Check training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:23.320445Z",
     "iopub.status.busy": "2023-07-27T04:53:23.320190Z",
     "iopub.status.idle": "2023-07-27T04:53:23.910515Z",
     "shell.execute_reply": "2023-07-27T04:53:23.909717Z"
    },
    "id": "BBe9FMO5ucTC"
   },
   "outputs": [],
   "source": [
    "plot_metrics(weighted_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REy6WClTZIwQ"
   },
   "source": [
    "### Evaluate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:23.914596Z",
     "iopub.status.busy": "2023-07-27T04:53:23.914268Z",
     "iopub.status.idle": "2023-07-27T04:53:24.317498Z",
     "shell.execute_reply": "2023-07-27T04:53:24.316779Z"
    },
    "id": "nifqscPGw-5w"
   },
   "outputs": [],
   "source": [
    "train_predictions_weighted = weighted_model.predict(train_features, batch_size=BATCH_SIZE)\n",
    "test_predictions_weighted = weighted_model.predict(test_features, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:24.320967Z",
     "iopub.status.busy": "2023-07-27T04:53:24.320725Z",
     "iopub.status.idle": "2023-07-27T04:53:24.657163Z",
     "shell.execute_reply": "2023-07-27T04:53:24.656495Z"
    },
    "id": "owKL2vdMBJr6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.01430773176252842\n",
      "cross entropy :  0.01430773176252842\n",
      "Brier score :  0.0017187276389449835\n",
      "tp :  67.0\n",
      "fp :  65.0\n",
      "tn :  56809.0\n",
      "fn :  21.0\n",
      "accuracy :  0.9984902143478394\n",
      "precision :  0.5075757503509521\n",
      "recall :  0.7613636255264282\n",
      "auc :  0.9331508278846741\n",
      "prc :  0.6515186429023743\n",
      "\n",
      "Legitimate Transactions Detected (True Negatives):  56809\n",
      "Legitimate Transactions Incorrectly Detected (False Positives):  65\n",
      "Fraudulent Transactions Missed (False Negatives):  21\n",
      "Fraudulent Transactions Detected (True Positives):  67\n",
      "Total Fraudulent Transactions:  88\n"
     ]
    }
   ],
   "source": [
    "weighted_results = weighted_model.evaluate(test_features, test_labels,\n",
    "                                           batch_size=BATCH_SIZE, verbose=0)\n",
    "for name, value in zip(weighted_model.metrics_names, weighted_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(test_labels, test_predictions_weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTh1rtDn8r4-"
   },
   "source": [
    "Here you can see that with class weights the accuracy and precision are lower because there are more false positives, but conversely the recall and AUC are higher because the model also found more true positives. Despite having lower accuracy, this model has higher recall (and identifies more fraudulent transactions than the baseline model at threshold 50%). Of course, there is a cost to both types of error (you wouldn't want to bug users by flagging too many legitimate transactions as fraudulent, either). Carefully consider the trade-offs between these different types of errors for your application.\n",
    "\n",
    "Compared to the baseline model with changed threshold, the class weighted model is clearly inferior. The superiority of the baseline model is further confirmed by the lower test loss value (cross entropy and mean squared error) and additionally can be seen by plotting the ROC curves of both models together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXDAwyr0HYdX"
   },
   "source": [
    "### Plot the ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:24.660757Z",
     "iopub.status.busy": "2023-07-27T04:53:24.660183Z",
     "iopub.status.idle": "2023-07-27T04:53:24.981593Z",
     "shell.execute_reply": "2023-07-27T04:53:24.980925Z"
    },
    "id": "3hzScIVZS1Xm"
   },
   "outputs": [],
   "source": [
    "plot_roc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\n",
    "plot_roc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\n",
    "\n",
    "plot_roc(\"Train Weighted\", train_labels, train_predictions_weighted, color=colors[1])\n",
    "plot_roc(\"Test Weighted\", test_labels, test_predictions_weighted, color=colors[1], linestyle='--')\n",
    "\n",
    "\n",
    "plt.legend(loc='lower right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0krS8g1OTbD"
   },
   "source": [
    "### Plot the PRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:24.985665Z",
     "iopub.status.busy": "2023-07-27T04:53:24.985139Z",
     "iopub.status.idle": "2023-07-27T04:53:25.550248Z",
     "shell.execute_reply": "2023-07-27T04:53:25.549571Z"
    },
    "id": "7jHnmVebOWOC"
   },
   "outputs": [],
   "source": [
    "plot_prc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\n",
    "plot_prc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\n",
    "\n",
    "plot_prc(\"Train Weighted\", train_labels, train_predictions_weighted, color=colors[1])\n",
    "plot_prc(\"Test Weighted\", test_labels, test_predictions_weighted, color=colors[1], linestyle='--')\n",
    "\n",
    "\n",
    "plt.legend(loc='lower right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ysRtr6xHnXP"
   },
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18VUHNc-UF5w"
   },
   "source": [
    "### Oversample the minority class\n",
    "\n",
    "A related approach would be to resample the dataset by oversampling the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:25.554219Z",
     "iopub.status.busy": "2023-07-27T04:53:25.553626Z",
     "iopub.status.idle": "2023-07-27T04:53:25.578056Z",
     "shell.execute_reply": "2023-07-27T04:53:25.577261Z"
    },
    "id": "sHirNp6u7OWp"
   },
   "outputs": [],
   "source": [
    "pos_features = train_features[bool_train_labels]\n",
    "neg_features = train_features[~bool_train_labels]\n",
    "\n",
    "pos_labels = train_labels[bool_train_labels]\n",
    "neg_labels = train_labels[~bool_train_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgBVbX7P7QrL"
   },
   "source": [
    "#### Using NumPy\n",
    "\n",
    "You can balance the dataset manually by choosing the right number of random \n",
    "indices from the positive examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:25.582295Z",
     "iopub.status.busy": "2023-07-27T04:53:25.581684Z",
     "iopub.status.idle": "2023-07-27T04:53:25.606113Z",
     "shell.execute_reply": "2023-07-27T04:53:25.605470Z"
    },
    "id": "BUzGjSkwqT88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181952, 29)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = np.arange(len(pos_features))\n",
    "choices = np.random.choice(ids, len(neg_features))\n",
    "\n",
    "res_pos_features = pos_features[choices]\n",
    "res_pos_labels = pos_labels[choices]\n",
    "\n",
    "res_pos_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:25.609779Z",
     "iopub.status.busy": "2023-07-27T04:53:25.609179Z",
     "iopub.status.idle": "2023-07-27T04:53:25.716726Z",
     "shell.execute_reply": "2023-07-27T04:53:25.716036Z"
    },
    "id": "7ie_FFet6cep"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363904, 29)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_features = np.concatenate([res_pos_features, neg_features], axis=0)\n",
    "resampled_labels = np.concatenate([res_pos_labels, neg_labels], axis=0)\n",
    "\n",
    "order = np.arange(len(resampled_labels))\n",
    "np.random.shuffle(order)\n",
    "resampled_features = resampled_features[order]\n",
    "resampled_labels = resampled_labels[order]\n",
    "\n",
    "resampled_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYfJe2Kc-FAz"
   },
   "source": [
    "#### Using `tf.data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usyixaST8v5P"
   },
   "source": [
    "If you're using `tf.data` the easiest way to produce balanced examples is to start with a `positive` and a `negative` dataset, and merge them. See [the tf.data guide](../../guide/data.ipynb) for more examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:25.720318Z",
     "iopub.status.busy": "2023-07-27T04:53:25.720074Z",
     "iopub.status.idle": "2023-07-27T04:53:25.835970Z",
     "shell.execute_reply": "2023-07-27T04:53:25.835284Z"
    },
    "id": "yF4OZ-rI6xb6"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 100000\n",
    "\n",
    "def make_ds(features, labels):\n",
    "  ds = tf.data.Dataset.from_tensor_slices((features, labels))#.cache()\n",
    "  ds = ds.shuffle(BUFFER_SIZE).repeat()\n",
    "  return ds\n",
    "\n",
    "pos_ds = make_ds(pos_features, pos_labels)\n",
    "neg_ds = make_ds(neg_features, neg_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNQUx-OA-oJc"
   },
   "source": [
    "Each dataset provides `(feature, label)` pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:25.839360Z",
     "iopub.status.busy": "2023-07-27T04:53:25.839128Z",
     "iopub.status.idle": "2023-07-27T04:53:25.856693Z",
     "shell.execute_reply": "2023-07-27T04:53:25.856098Z"
    },
    "id": "llXc9rNH7Fbz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      " [ 0.46472293  0.81550675 -2.95071301  2.28739561 -0.2992301  -0.57106041\n",
      " -2.01083659  0.57906356 -0.42613824 -4.21071648  3.53667336 -3.17272142\n",
      " -0.40242779 -5.         -1.76491846 -2.73341618 -3.04144885  0.11153868\n",
      "  0.12002991  0.57712318  0.79499453  0.82023752 -0.40678325  0.5373592\n",
      "  1.08270136 -0.53288148  1.61334844  0.99605094  0.62944734]\n",
      "\n",
      "Label:  1\n"
     ]
    }
   ],
   "source": [
    "for features, label in pos_ds.take(1):\n",
    "  print(\"Features:\\n\", features.numpy())\n",
    "  print()\n",
    "  print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLEfjZO0-vbN"
   },
   "source": [
    "Merge the two together using `tf.data.Dataset.sample_from_datasets`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:25.860155Z",
     "iopub.status.busy": "2023-07-27T04:53:25.859533Z",
     "iopub.status.idle": "2023-07-27T04:53:25.881011Z",
     "shell.execute_reply": "2023-07-27T04:53:25.880423Z"
    },
    "id": "e7w9UQPT9wzE"
   },
   "outputs": [],
   "source": [
    "resampled_ds = tf.data.Dataset.sample_from_datasets([pos_ds, neg_ds], weights=[0.5, 0.5])\n",
    "resampled_ds = resampled_ds.batch(BATCH_SIZE).prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:25.883924Z",
     "iopub.status.busy": "2023-07-27T04:53:25.883696Z",
     "iopub.status.idle": "2023-07-27T04:53:26.147342Z",
     "shell.execute_reply": "2023-07-27T04:53:26.146428Z"
    },
    "id": "EWXARdTdAuQK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4814453125\n"
     ]
    }
   ],
   "source": [
    "for features, label in resampled_ds.take(1):\n",
    "  print(label.numpy().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irgqf3YxAyN0"
   },
   "source": [
    "To use this dataset, you'll need the number of steps per epoch.\n",
    "\n",
    "The definition of \"epoch\" in this case is less clear. Say it's the number of batches required to see each negative example once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:26.150810Z",
     "iopub.status.busy": "2023-07-27T04:53:26.150536Z",
     "iopub.status.idle": "2023-07-27T04:53:26.155065Z",
     "shell.execute_reply": "2023-07-27T04:53:26.154446Z"
    },
    "id": "xH-7K46AAxpq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_steps_per_epoch = np.ceil(2.0*neg/BATCH_SIZE)\n",
    "resampled_steps_per_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZ1BvEpcBVHP"
   },
   "source": [
    "### Train on the oversampled data\n",
    "\n",
    "Now try training the model with the resampled data set instead of using class weights to see how these methods compare.\n",
    "\n",
    "Note: Because the data was balanced by replicating the positive examples, the total dataset size is larger, and each epoch runs for more training steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:53:26.158153Z",
     "iopub.status.busy": "2023-07-27T04:53:26.157589Z",
     "iopub.status.idle": "2023-07-27T04:54:30.202190Z",
     "shell.execute_reply": "2023-07-27T04:54:30.201466Z"
    },
    "id": "soRQ89JYqd6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "278/278 [==============================] - 10s 26ms/step - loss: 0.5057 - cross entropy: 0.4610 - Brier score: 0.1407 - tp: 222017.0000 - fp: 62708.0000 - tn: 278588.0000 - fn: 62993.0000 - accuracy: 0.7993 - precision: 0.7798 - recall: 0.7790 - auc: 0.8706 - prc: 0.8952 - val_loss: 0.2036 - val_cross entropy: 0.2036 - val_Brier score: 0.0447 - val_tp: 74.0000 - val_fp: 1188.0000 - val_tn: 44301.0000 - val_fn: 6.0000 - val_accuracy: 0.9738 - val_precision: 0.0586 - val_recall: 0.9250 - val_auc: 0.9751 - val_prc: 0.7542\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 6s 22ms/step - loss: 0.2104 - cross entropy: 0.2104 - Brier score: 0.0637 - tp: 256734.0000 - fp: 18630.0000 - tn: 265556.0000 - fn: 28424.0000 - accuracy: 0.9174 - precision: 0.9323 - recall: 0.9003 - auc: 0.9699 - prc: 0.9762 - val_loss: 0.1153 - val_cross entropy: 0.1153 - val_Brier score: 0.0237 - val_tp: 73.0000 - val_fp: 865.0000 - val_tn: 44624.0000 - val_fn: 7.0000 - val_accuracy: 0.9809 - val_precision: 0.0778 - val_recall: 0.9125 - val_auc: 0.9748 - val_prc: 0.7579\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 6s 21ms/step - loss: 0.1582 - cross entropy: 0.1582 - Brier score: 0.0470 - tp: 261708.0000 - fp: 11327.0000 - tn: 273431.0000 - fn: 22878.0000 - accuracy: 0.9399 - precision: 0.9585 - recall: 0.9196 - auc: 0.9835 - prc: 0.9860 - val_loss: 0.0890 - val_cross entropy: 0.0890 - val_Brier score: 0.0188 - val_tp: 73.0000 - val_fp: 775.0000 - val_tn: 44714.0000 - val_fn: 7.0000 - val_accuracy: 0.9828 - val_precision: 0.0861 - val_recall: 0.9125 - val_auc: 0.9738 - val_prc: 0.7666\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 6s 21ms/step - loss: 0.1357 - cross entropy: 0.1357 - Brier score: 0.0405 - tp: 264958.0000 - fp: 9243.0000 - tn: 274698.0000 - fn: 20445.0000 - accuracy: 0.9479 - precision: 0.9663 - recall: 0.9284 - auc: 0.9883 - prc: 0.9896 - val_loss: 0.0767 - val_cross entropy: 0.0767 - val_Brier score: 0.0166 - val_tp: 73.0000 - val_fp: 736.0000 - val_tn: 44753.0000 - val_fn: 7.0000 - val_accuracy: 0.9837 - val_precision: 0.0902 - val_recall: 0.9125 - val_auc: 0.9713 - val_prc: 0.7495\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 5s 20ms/step - loss: 0.1225 - cross entropy: 0.1225 - Brier score: 0.0366 - tp: 265275.0000 - fp: 8123.0000 - tn: 276678.0000 - fn: 19268.0000 - accuracy: 0.9519 - precision: 0.9703 - recall: 0.9323 - auc: 0.9909 - prc: 0.9916 - val_loss: 0.0689 - val_cross entropy: 0.0689 - val_Brier score: 0.0153 - val_tp: 73.0000 - val_fp: 716.0000 - val_tn: 44773.0000 - val_fn: 7.0000 - val_accuracy: 0.9841 - val_precision: 0.0925 - val_recall: 0.9125 - val_auc: 0.9679 - val_prc: 0.7408\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 6s 20ms/step - loss: 0.1125 - cross entropy: 0.1125 - Brier score: 0.0335 - tp: 267205.0000 - fp: 7499.0000 - tn: 277214.0000 - fn: 17426.0000 - accuracy: 0.9562 - precision: 0.9727 - recall: 0.9388 - auc: 0.9926 - prc: 0.9930 - val_loss: 0.0627 - val_cross entropy: 0.0627 - val_Brier score: 0.0142 - val_tp: 73.0000 - val_fp: 686.0000 - val_tn: 44803.0000 - val_fn: 7.0000 - val_accuracy: 0.9848 - val_precision: 0.0962 - val_recall: 0.9125 - val_auc: 0.9648 - val_prc: 0.7325\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 5s 19ms/step - loss: 0.1049 - cross entropy: 0.1049 - Brier score: 0.0312 - tp: 268006.0000 - fp: 7137.0000 - tn: 277906.0000 - fn: 16295.0000 - accuracy: 0.9588 - precision: 0.9741 - recall: 0.9427 - auc: 0.9938 - prc: 0.9938 - val_loss: 0.0590 - val_cross entropy: 0.0590 - val_Brier score: 0.0135 - val_tp: 73.0000 - val_fp: 673.0000 - val_tn: 44816.0000 - val_fn: 7.0000 - val_accuracy: 0.9851 - val_precision: 0.0979 - val_recall: 0.9125 - val_auc: 0.9621 - val_prc: 0.7111\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 6s 21ms/step - loss: 0.0996 - cross entropy: 0.0996 - Brier score: 0.0298 - tp: 269055.0000 - fp: 6921.0000 - tn: 277572.0000 - fn: 15796.0000 - accuracy: 0.9601 - precision: 0.9749 - recall: 0.9445 - auc: 0.9945 - prc: 0.9944 - val_loss: 0.0542 - val_cross entropy: 0.0542 - val_Brier score: 0.0124 - val_tp: 73.0000 - val_fp: 608.0000 - val_tn: 44881.0000 - val_fn: 7.0000 - val_accuracy: 0.9865 - val_precision: 0.1072 - val_recall: 0.9125 - val_auc: 0.9633 - val_prc: 0.6963\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 6s 23ms/step - loss: 0.0949 - cross entropy: 0.0949 - Brier score: 0.0283 - tp: 269182.0000 - fp: 6692.0000 - tn: 278492.0000 - fn: 14978.0000 - accuracy: 0.9619 - precision: 0.9757 - recall: 0.9473 - auc: 0.9950 - prc: 0.9949 - val_loss: 0.0505 - val_cross entropy: 0.0505 - val_Brier score: 0.0116 - val_tp: 73.0000 - val_fp: 593.0000 - val_tn: 44896.0000 - val_fn: 7.0000 - val_accuracy: 0.9868 - val_precision: 0.1096 - val_recall: 0.9125 - val_auc: 0.9642 - val_prc: 0.6962\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 6s 22ms/step - loss: 0.0908 - cross entropy: 0.0908 - Brier score: 0.0272 - tp: 269993.0000 - fp: 6498.0000 - tn: 278379.0000 - fn: 14474.0000 - accuracy: 0.9632 - precision: 0.9765 - recall: 0.9491 - auc: 0.9955 - prc: 0.9952 - val_loss: 0.0476 - val_cross entropy: 0.0476 - val_Brier score: 0.0110 - val_tp: 73.0000 - val_fp: 571.0000 - val_tn: 44918.0000 - val_fn: 7.0000 - val_accuracy: 0.9873 - val_precision: 0.1134 - val_recall: 0.9125 - val_auc: 0.9651 - val_prc: 0.6888\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 5s 19ms/step - loss: 0.0868 - cross entropy: 0.0868 - Brier score: 0.0259 - tp: 270945.0000 - fp: 6262.0000 - tn: 278667.0000 - fn: 13470.0000 - accuracy: 0.9653 - precision: 0.9774 - recall: 0.9526 - auc: 0.9959 - prc: 0.9956 - val_loss: 0.0450 - val_cross entropy: 0.0450 - val_Brier score: 0.0104 - val_tp: 73.0000 - val_fp: 542.0000 - val_tn: 44947.0000 - val_fn: 7.0000 - val_accuracy: 0.9880 - val_precision: 0.1187 - val_recall: 0.9125 - val_auc: 0.9658 - val_prc: 0.6895\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 6s 23ms/step - loss: 0.0832 - cross entropy: 0.0832 - Brier score: 0.0248 - tp: 272291.0000 - fp: 6147.0000 - tn: 277998.0000 - fn: 12908.0000 - accuracy: 0.9665 - precision: 0.9779 - recall: 0.9547 - auc: 0.9962 - prc: 0.9959 - val_loss: 0.0418 - val_cross entropy: 0.0418 - val_Brier score: 0.0096 - val_tp: 73.0000 - val_fp: 501.0000 - val_tn: 44988.0000 - val_fn: 7.0000 - val_accuracy: 0.9889 - val_precision: 0.1272 - val_recall: 0.9125 - val_auc: 0.9667 - val_prc: 0.6899\n",
      "Epoch 13/100\n",
      "277/278 [============================>.] - ETA: 0s - loss: 0.0800 - cross entropy: 0.0800 - Brier score: 0.0239 - tp: 271557.0000 - fp: 6074.0000 - tn: 277391.0000 - fn: 12274.0000 - accuracy: 0.9677 - precision: 0.9781 - recall: 0.9568 - auc: 0.9965 - prc: 0.9961Restoring model weights from the end of the best epoch: 3.\n",
      "278/278 [==============================] - 7s 24ms/step - loss: 0.0800 - cross entropy: 0.0800 - Brier score: 0.0239 - tp: 272536.0000 - fp: 6094.0000 - tn: 278396.0000 - fn: 12318.0000 - accuracy: 0.9677 - precision: 0.9781 - recall: 0.9568 - auc: 0.9965 - prc: 0.9961 - val_loss: 0.0398 - val_cross entropy: 0.0398 - val_Brier score: 0.0091 - val_tp: 73.0000 - val_fp: 483.0000 - val_tn: 45006.0000 - val_fn: 7.0000 - val_accuracy: 0.9892 - val_precision: 0.1313 - val_recall: 0.9125 - val_auc: 0.9675 - val_prc: 0.6825\n",
      "Epoch 13: early stopping\n"
     ]
    }
   ],
   "source": [
    "resampled_model = make_model()\n",
    "resampled_model.load_weights(initial_weights)\n",
    "\n",
    "# Reset the bias to zero, since this dataset is balanced.\n",
    "output_layer = resampled_model.layers[-1] \n",
    "output_layer.bias.assign([0])\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((val_features, val_labels)).cache()\n",
    "val_ds = val_ds.batch(BATCH_SIZE).prefetch(2) \n",
    "\n",
    "resampled_history = resampled_model.fit(\n",
    "    resampled_ds,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=resampled_steps_per_epoch,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "avALvzUp3T_c"
   },
   "source": [
    "If the training process were considering the whole dataset on each gradient update, this oversampling would be basically identical to the class weighting.\n",
    "\n",
    "But when training the model batch-wise, as you did here, the oversampled data provides a smoother gradient signal: Instead of each positive example being shown in one batch with a large weight, they're shown in many different batches each time with a small weight. \n",
    "\n",
    "This smoother gradient signal makes it easier to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klHZ0HV76VC5"
   },
   "source": [
    "### Check training history\n",
    "\n",
    "Note that the distributions of metrics will be different here, because the training data has a totally different distribution from the validation and test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:54:30.205864Z",
     "iopub.status.busy": "2023-07-27T04:54:30.205343Z",
     "iopub.status.idle": "2023-07-27T04:54:30.894926Z",
     "shell.execute_reply": "2023-07-27T04:54:30.894200Z"
    },
    "id": "YoUGfr1vuivl"
   },
   "outputs": [],
   "source": [
    "plot_metrics(resampled_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PuH3A2vnwrh"
   },
   "source": [
    "### Re-train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFLxRL8eoDE5"
   },
   "source": [
    "Because training is easier on the balanced data, the above training procedure may overfit quickly. \n",
    "\n",
    "So break up the epochs to give the `tf.keras.callbacks.EarlyStopping` finer control over when to stop training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:54:30.898877Z",
     "iopub.status.busy": "2023-07-27T04:54:30.898286Z",
     "iopub.status.idle": "2023-07-27T04:54:45.911522Z",
     "shell.execute_reply": "2023-07-27T04:54:45.910772Z"
    },
    "id": "e_yn9I26qAHU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "20/20 [==============================] - 3s 65ms/step - loss: 1.3919 - cross entropy: 0.6798 - Brier score: 0.1764 - tp: 7566.0000 - fp: 7372.0000 - tn: 58483.0000 - fn: 13108.0000 - accuracy: 0.7633 - precision: 0.5065 - recall: 0.3660 - auc: 0.7560 - prc: 0.5306 - val_loss: 0.5075 - val_cross entropy: 0.5075 - val_Brier score: 0.1656 - val_tp: 50.0000 - val_fp: 9917.0000 - val_tn: 35572.0000 - val_fn: 30.0000 - val_accuracy: 0.7817 - val_precision: 0.0050 - val_recall: 0.6250 - val_auc: 0.7433 - val_prc: 0.0177\n",
      "Epoch 2/1000\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.8839 - cross entropy: 0.8839 - Brier score: 0.2680 - tp: 11762.0000 - fp: 7370.0000 - tn: 13247.0000 - fn: 8581.0000 - accuracy: 0.6106 - precision: 0.6148 - recall: 0.5782 - auc: 0.6301 - prc: 0.7300 - val_loss: 0.5157 - val_cross entropy: 0.5157 - val_Brier score: 0.1685 - val_tp: 70.0000 - val_fp: 10081.0000 - val_tn: 35408.0000 - val_fn: 10.0000 - val_accuracy: 0.7786 - val_precision: 0.0069 - val_recall: 0.8750 - val_auc: 0.9213 - val_prc: 0.3221\n",
      "Epoch 3/1000\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.6723 - cross entropy: 0.6723 - Brier score: 0.2150 - tp: 14407.0000 - fp: 7179.0000 - tn: 13374.0000 - fn: 6000.0000 - accuracy: 0.6782 - precision: 0.6674 - recall: 0.7060 - auc: 0.7442 - prc: 0.8181 - val_loss: 0.4936 - val_cross entropy: 0.4936 - val_Brier score: 0.1581 - val_tp: 73.0000 - val_fp: 8627.0000 - val_tn: 36862.0000 - val_fn: 7.0000 - val_accuracy: 0.8105 - val_precision: 0.0084 - val_recall: 0.9125 - val_auc: 0.9480 - val_prc: 0.5352\n",
      "Epoch 4/1000\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.5680 - cross entropy: 0.5680 - Brier score: 0.1838 - tp: 15760.0000 - fp: 6512.0000 - tn: 13878.0000 - fn: 4810.0000 - accuracy: 0.7236 - precision: 0.7076 - recall: 0.7662 - auc: 0.8053 - prc: 0.8642 - val_loss: 0.4585 - val_cross entropy: 0.4585 - val_Brier score: 0.1421 - val_tp: 74.0000 - val_fp: 6644.0000 - val_tn: 38845.0000 - val_fn: 6.0000 - val_accuracy: 0.8541 - val_precision: 0.0110 - val_recall: 0.9250 - val_auc: 0.9566 - val_prc: 0.6018\n",
      "Epoch 5/1000\n",
      "20/20 [==============================] - 0s 25ms/step - loss: 0.5061 - cross entropy: 0.5061 - Brier score: 0.1643 - tp: 16241.0000 - fp: 5920.0000 - tn: 14592.0000 - fn: 4207.0000 - accuracy: 0.7528 - precision: 0.7329 - recall: 0.7943 - auc: 0.8412 - prc: 0.8898 - val_loss: 0.4207 - val_cross entropy: 0.4207 - val_Brier score: 0.1253 - val_tp: 74.0000 - val_fp: 4794.0000 - val_tn: 40695.0000 - val_fn: 6.0000 - val_accuracy: 0.8947 - val_precision: 0.0152 - val_recall: 0.9250 - val_auc: 0.9635 - val_prc: 0.6673\n",
      "Epoch 6/1000\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4552 - cross entropy: 0.4552 - Brier score: 0.1469 - tp: 16598.0000 - fp: 4955.0000 - tn: 15545.0000 - fn: 3862.0000 - accuracy: 0.7847 - precision: 0.7701 - recall: 0.8112 - auc: 0.8686 - prc: 0.9091 - val_loss: 0.3835 - val_cross entropy: 0.3835 - val_Brier score: 0.1094 - val_tp: 74.0000 - val_fp: 3276.0000 - val_tn: 42213.0000 - val_fn: 6.0000 - val_accuracy: 0.9280 - val_precision: 0.0221 - val_recall: 0.9250 - val_auc: 0.9681 - val_prc: 0.6964\n",
      "Epoch 7/1000\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.4117 - cross entropy: 0.4117 - Brier score: 0.1324 - tp: 16950.0000 - fp: 4242.0000 - tn: 16229.0000 - fn: 3539.0000 - accuracy: 0.8100 - precision: 0.7998 - recall: 0.8273 - auc: 0.8891 - prc: 0.9233 - val_loss: 0.3490 - val_cross entropy: 0.3490 - val_Brier score: 0.0952 - val_tp: 74.0000 - val_fp: 2437.0000 - val_tn: 43052.0000 - val_fn: 6.0000 - val_accuracy: 0.9464 - val_precision: 0.0295 - val_recall: 0.9250 - val_auc: 0.9712 - val_prc: 0.7153\n",
      "Epoch 8/1000\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.3709 - cross entropy: 0.3709 - Brier score: 0.1192 - tp: 17324.0000 - fp: 3817.0000 - tn: 16623.0000 - fn: 3196.0000 - accuracy: 0.8288 - precision: 0.8195 - recall: 0.8442 - auc: 0.9082 - prc: 0.9357 - val_loss: 0.3180 - val_cross entropy: 0.3180 - val_Brier score: 0.0830 - val_tp: 75.0000 - val_fp: 2000.0000 - val_tn: 43489.0000 - val_fn: 5.0000 - val_accuracy: 0.9560 - val_precision: 0.0361 - val_recall: 0.9375 - val_auc: 0.9723 - val_prc: 0.7192\n",
      "Epoch 9/1000\n",
      "20/20 [==============================] - 0s 26ms/step - loss: 0.3478 - cross entropy: 0.3478 - Brier score: 0.1105 - tp: 17542.0000 - fp: 3439.0000 - tn: 17061.0000 - fn: 2918.0000 - accuracy: 0.8448 - precision: 0.8361 - recall: 0.8574 - auc: 0.9198 - prc: 0.9435 - val_loss: 0.2910 - val_cross entropy: 0.2910 - val_Brier score: 0.0729 - val_tp: 74.0000 - val_fp: 1690.0000 - val_tn: 43799.0000 - val_fn: 6.0000 - val_accuracy: 0.9628 - val_precision: 0.0420 - val_recall: 0.9250 - val_auc: 0.9731 - val_prc: 0.7287\n",
      "Epoch 10/1000\n",
      "20/20 [==============================] - 0s 25ms/step - loss: 0.3223 - cross entropy: 0.3223 - Brier score: 0.1017 - tp: 17714.0000 - fp: 3034.0000 - tn: 17484.0000 - fn: 2728.0000 - accuracy: 0.8593 - precision: 0.8538 - recall: 0.8665 - auc: 0.9300 - prc: 0.9503 - val_loss: 0.2664 - val_cross entropy: 0.2664 - val_Brier score: 0.0642 - val_tp: 74.0000 - val_fp: 1468.0000 - val_tn: 44021.0000 - val_fn: 6.0000 - val_accuracy: 0.9677 - val_precision: 0.0480 - val_recall: 0.9250 - val_auc: 0.9738 - val_prc: 0.7370\n",
      "Epoch 11/1000\n",
      "20/20 [==============================] - 0s 25ms/step - loss: 0.3063 - cross entropy: 0.3063 - Brier score: 0.0963 - tp: 17723.0000 - fp: 2659.0000 - tn: 17887.0000 - fn: 2691.0000 - accuracy: 0.8694 - precision: 0.8695 - recall: 0.8682 - auc: 0.9352 - prc: 0.9535 - val_loss: 0.2465 - val_cross entropy: 0.2465 - val_Brier score: 0.0576 - val_tp: 74.0000 - val_fp: 1345.0000 - val_tn: 44144.0000 - val_fn: 6.0000 - val_accuracy: 0.9704 - val_precision: 0.0521 - val_recall: 0.9250 - val_auc: 0.9744 - val_prc: 0.7449\n",
      "Epoch 12/1000\n",
      "20/20 [==============================] - 0s 26ms/step - loss: 0.2873 - cross entropy: 0.2873 - Brier score: 0.0893 - tp: 17899.0000 - fp: 2385.0000 - tn: 18121.0000 - fn: 2555.0000 - accuracy: 0.8794 - precision: 0.8824 - recall: 0.8751 - auc: 0.9435 - prc: 0.9588 - val_loss: 0.2298 - val_cross entropy: 0.2298 - val_Brier score: 0.0524 - val_tp: 74.0000 - val_fp: 1291.0000 - val_tn: 44198.0000 - val_fn: 6.0000 - val_accuracy: 0.9715 - val_precision: 0.0542 - val_recall: 0.9250 - val_auc: 0.9744 - val_prc: 0.7466\n",
      "Epoch 13/1000\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2764 - cross entropy: 0.2764 - Brier score: 0.0859 - tp: 17941.0000 - fp: 2193.0000 - tn: 18267.0000 - fn: 2559.0000 - accuracy: 0.8840 - precision: 0.8911 - recall: 0.8752 - auc: 0.9475 - prc: 0.9612 - val_loss: 0.2146 - val_cross entropy: 0.2146 - val_Brier score: 0.0478 - val_tp: 74.0000 - val_fp: 1231.0000 - val_tn: 44258.0000 - val_fn: 6.0000 - val_accuracy: 0.9729 - val_precision: 0.0567 - val_recall: 0.9250 - val_auc: 0.9746 - val_prc: 0.7508\n",
      "Epoch 14/1000\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.2627 - cross entropy: 0.2627 - Brier score: 0.0810 - tp: 18117.0000 - fp: 2046.0000 - tn: 18353.0000 - fn: 2444.0000 - accuracy: 0.8904 - precision: 0.8985 - recall: 0.8811 - auc: 0.9526 - prc: 0.9646 - val_loss: 0.2019 - val_cross entropy: 0.2019 - val_Brier score: 0.0442 - val_tp: 74.0000 - val_fp: 1186.0000 - val_tn: 44303.0000 - val_fn: 6.0000 - val_accuracy: 0.9738 - val_precision: 0.0587 - val_recall: 0.9250 - val_auc: 0.9750 - val_prc: 0.7548\n",
      "Epoch 15/1000\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.2531 - cross entropy: 0.2531 - Brier score: 0.0781 - tp: 18109.0000 - fp: 1868.0000 - tn: 18596.0000 - fn: 2387.0000 - accuracy: 0.8961 - precision: 0.9065 - recall: 0.8835 - auc: 0.9555 - prc: 0.9665 - val_loss: 0.1914 - val_cross entropy: 0.1914 - val_Brier score: 0.0414 - val_tp: 73.0000 - val_fp: 1176.0000 - val_tn: 44313.0000 - val_fn: 7.0000 - val_accuracy: 0.9740 - val_precision: 0.0584 - val_recall: 0.9125 - val_auc: 0.9749 - val_prc: 0.7574\n",
      "Epoch 16/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 23ms/step - loss: 0.2451 - cross entropy: 0.2451 - Brier score: 0.0751 - tp: 18204.0000 - fp: 1781.0000 - tn: 18669.0000 - fn: 2306.0000 - accuracy: 0.9002 - precision: 0.9109 - recall: 0.8876 - auc: 0.9586 - prc: 0.9686 - val_loss: 0.1809 - val_cross entropy: 0.1809 - val_Brier score: 0.0387 - val_tp: 73.0000 - val_fp: 1136.0000 - val_tn: 44353.0000 - val_fn: 7.0000 - val_accuracy: 0.9749 - val_precision: 0.0604 - val_recall: 0.9125 - val_auc: 0.9752 - val_prc: 0.7603\n",
      "Epoch 17/1000\n",
      "20/20 [==============================] - 0s 26ms/step - loss: 0.2300 - cross entropy: 0.2300 - Brier score: 0.0702 - tp: 18280.0000 - fp: 1538.0000 - tn: 18951.0000 - fn: 2191.0000 - accuracy: 0.9090 - precision: 0.9224 - recall: 0.8930 - auc: 0.9636 - prc: 0.9718 - val_loss: 0.1715 - val_cross entropy: 0.1715 - val_Brier score: 0.0362 - val_tp: 73.0000 - val_fp: 1098.0000 - val_tn: 44391.0000 - val_fn: 7.0000 - val_accuracy: 0.9758 - val_precision: 0.0623 - val_recall: 0.9125 - val_auc: 0.9752 - val_prc: 0.7635\n",
      "Epoch 18/1000\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.2233 - cross entropy: 0.2233 - Brier score: 0.0681 - tp: 18274.0000 - fp: 1507.0000 - tn: 19056.0000 - fn: 2123.0000 - accuracy: 0.9114 - precision: 0.9238 - recall: 0.8959 - auc: 0.9661 - prc: 0.9735 - val_loss: 0.1629 - val_cross entropy: 0.1629 - val_Brier score: 0.0341 - val_tp: 73.0000 - val_fp: 1061.0000 - val_tn: 44428.0000 - val_fn: 7.0000 - val_accuracy: 0.9766 - val_precision: 0.0644 - val_recall: 0.9125 - val_auc: 0.9757 - val_prc: 0.7643\n",
      "Epoch 19/1000\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.2192 - cross entropy: 0.2192 - Brier score: 0.0663 - tp: 18448.0000 - fp: 1423.0000 - tn: 18970.0000 - fn: 2119.0000 - accuracy: 0.9135 - precision: 0.9284 - recall: 0.8970 - auc: 0.9674 - prc: 0.9746 - val_loss: 0.1563 - val_cross entropy: 0.1563 - val_Brier score: 0.0326 - val_tp: 73.0000 - val_fp: 1052.0000 - val_tn: 44437.0000 - val_fn: 7.0000 - val_accuracy: 0.9768 - val_precision: 0.0649 - val_recall: 0.9125 - val_auc: 0.9756 - val_prc: 0.7557\n",
      "Epoch 20/1000\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.2093 - cross entropy: 0.2093 - Brier score: 0.0637 - tp: 18683.0000 - fp: 1354.0000 - tn: 18912.0000 - fn: 2011.0000 - accuracy: 0.9178 - precision: 0.9324 - recall: 0.9028 - auc: 0.9700 - prc: 0.9769 - val_loss: 0.1503 - val_cross entropy: 0.1503 - val_Brier score: 0.0313 - val_tp: 73.0000 - val_fp: 1038.0000 - val_tn: 44451.0000 - val_fn: 7.0000 - val_accuracy: 0.9771 - val_precision: 0.0657 - val_recall: 0.9125 - val_auc: 0.9757 - val_prc: 0.7474\n",
      "Epoch 21/1000\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.2078 - cross entropy: 0.2078 - Brier score: 0.0626 - tp: 18371.0000 - fp: 1296.0000 - tn: 19283.0000 - fn: 2010.0000 - accuracy: 0.9193 - precision: 0.9341 - recall: 0.9014 - auc: 0.9707 - prc: 0.9764 - val_loss: 0.1453 - val_cross entropy: 0.1453 - val_Brier score: 0.0302 - val_tp: 73.0000 - val_fp: 1027.0000 - val_tn: 44462.0000 - val_fn: 7.0000 - val_accuracy: 0.9773 - val_precision: 0.0664 - val_recall: 0.9125 - val_auc: 0.9756 - val_prc: 0.7493\n",
      "Epoch 22/1000\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.2008 - cross entropy: 0.2008 - Brier score: 0.0604 - tp: 18554.0000 - fp: 1279.0000 - tn: 19229.0000 - fn: 1898.0000 - accuracy: 0.9224 - precision: 0.9355 - recall: 0.9072 - auc: 0.9731 - prc: 0.9785 - val_loss: 0.1383 - val_cross entropy: 0.1383 - val_Brier score: 0.0285 - val_tp: 73.0000 - val_fp: 972.0000 - val_tn: 44517.0000 - val_fn: 7.0000 - val_accuracy: 0.9785 - val_precision: 0.0699 - val_recall: 0.9125 - val_auc: 0.9754 - val_prc: 0.7499\n",
      "Epoch 23/1000\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.1961 - cross entropy: 0.1961 - Brier score: 0.0587 - tp: 18616.0000 - fp: 1176.0000 - tn: 19324.0000 - fn: 1844.0000 - accuracy: 0.9263 - precision: 0.9406 - recall: 0.9099 - auc: 0.9739 - prc: 0.9789 - val_loss: 0.1323 - val_cross entropy: 0.1323 - val_Brier score: 0.0270 - val_tp: 73.0000 - val_fp: 920.0000 - val_tn: 44569.0000 - val_fn: 7.0000 - val_accuracy: 0.9797 - val_precision: 0.0735 - val_recall: 0.9125 - val_auc: 0.9754 - val_prc: 0.7590\n",
      "Epoch 24/1000\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.1955 - cross entropy: 0.1955 - Brier score: 0.0587 - tp: 18592.0000 - fp: 1151.0000 - tn: 19306.0000 - fn: 1911.0000 - accuracy: 0.9252 - precision: 0.9417 - recall: 0.9068 - auc: 0.9738 - prc: 0.9791 - val_loss: 0.1282 - val_cross entropy: 0.1282 - val_Brier score: 0.0262 - val_tp: 73.0000 - val_fp: 911.0000 - val_tn: 44578.0000 - val_fn: 7.0000 - val_accuracy: 0.9799 - val_precision: 0.0742 - val_recall: 0.9125 - val_auc: 0.9755 - val_prc: 0.7594\n",
      "Epoch 25/1000\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.1870 - cross entropy: 0.1870 - Brier score: 0.0558 - tp: 18600.0000 - fp: 1099.0000 - tn: 19429.0000 - fn: 1832.0000 - accuracy: 0.9284 - precision: 0.9442 - recall: 0.9103 - auc: 0.9763 - prc: 0.9810 - val_loss: 0.1252 - val_cross entropy: 0.1252 - val_Brier score: 0.0258 - val_tp: 73.0000 - val_fp: 928.0000 - val_tn: 44561.0000 - val_fn: 7.0000 - val_accuracy: 0.9795 - val_precision: 0.0729 - val_recall: 0.9125 - val_auc: 0.9756 - val_prc: 0.7510\n",
      "Epoch 26/1000\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.1835 - cross entropy: 0.1835 - Brier score: 0.0545 - tp: 18696.0000 - fp: 1020.0000 - tn: 19432.0000 - fn: 1812.0000 - accuracy: 0.9309 - precision: 0.9483 - recall: 0.9116 - auc: 0.9775 - prc: 0.9815 - val_loss: 0.1217 - val_cross entropy: 0.1217 - val_Brier score: 0.0251 - val_tp: 73.0000 - val_fp: 920.0000 - val_tn: 44569.0000 - val_fn: 7.0000 - val_accuracy: 0.9797 - val_precision: 0.0735 - val_recall: 0.9125 - val_auc: 0.9754 - val_prc: 0.7557\n",
      "Epoch 27/1000\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 0.1786 - cross entropy: 0.1786 - Brier score: 0.0533 - tp: 18724.0000 - fp: 997.0000 - tn: 19474.0000 - fn: 1765.0000 - accuracy: 0.9326 - precision: 0.9494 - recall: 0.9139 - auc: 0.9787 - prc: 0.9825 - val_loss: 0.1178 - val_cross entropy: 0.1178 - val_Brier score: 0.0242 - val_tp: 73.0000 - val_fp: 888.0000 - val_tn: 44601.0000 - val_fn: 7.0000 - val_accuracy: 0.9804 - val_precision: 0.0760 - val_recall: 0.9125 - val_auc: 0.9746 - val_prc: 0.7578\n",
      "Epoch 28/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1783 - cross entropy: 0.1783 - Brier score: 0.0534 - tp: 18715.0000 - fp: 968.0000 - tn: 19475.0000 - fn: 1802.0000 - accuracy: 0.9324 - precision: 0.9508 - recall: 0.9122 - auc: 0.9785 - prc: 0.9823Restoring model weights from the end of the best epoch: 18.\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.1783 - cross entropy: 0.1783 - Brier score: 0.0534 - tp: 18715.0000 - fp: 968.0000 - tn: 19475.0000 - fn: 1802.0000 - accuracy: 0.9324 - precision: 0.9508 - recall: 0.9122 - auc: 0.9785 - prc: 0.9823 - val_loss: 0.1148 - val_cross entropy: 0.1148 - val_Brier score: 0.0236 - val_tp: 73.0000 - val_fp: 878.0000 - val_tn: 44611.0000 - val_fn: 7.0000 - val_accuracy: 0.9806 - val_precision: 0.0768 - val_recall: 0.9125 - val_auc: 0.9744 - val_prc: 0.7579\n",
      "Epoch 28: early stopping\n"
     ]
    }
   ],
   "source": [
    "resampled_model = make_model()\n",
    "resampled_model.load_weights(initial_weights)\n",
    "\n",
    "# Reset the bias to zero, since this dataset is balanced.\n",
    "output_layer = resampled_model.layers[-1] \n",
    "output_layer.bias.assign([0])\n",
    "\n",
    "resampled_history = resampled_model.fit(\n",
    "    resampled_ds,\n",
    "    # These are not real epochs\n",
    "    steps_per_epoch=20,\n",
    "    epochs=10*EPOCHS,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=(val_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UuJYKv0gpBK1"
   },
   "source": [
    "### Re-check training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:54:45.914945Z",
     "iopub.status.busy": "2023-07-27T04:54:45.914683Z",
     "iopub.status.idle": "2023-07-27T04:54:46.584295Z",
     "shell.execute_reply": "2023-07-27T04:54:46.583638Z"
    },
    "id": "FMycrpJwn39w"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-d9248335d864>:5: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(2,2,n+1)\n"
     ]
    }
   ],
   "source": [
    "plot_metrics(resampled_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUuE5HOWZiwP"
   },
   "source": [
    "### Evaluate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:54:46.588307Z",
     "iopub.status.busy": "2023-07-27T04:54:46.588058Z",
     "iopub.status.idle": "2023-07-27T04:54:47.001633Z",
     "shell.execute_reply": "2023-07-27T04:54:47.000947Z"
    },
    "id": "C0fmHSgXxFdW"
   },
   "outputs": [],
   "source": [
    "train_predictions_resampled = resampled_model.predict(train_features, batch_size=BATCH_SIZE)\n",
    "test_predictions_resampled = resampled_model.predict(test_features, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1315103 ,  0.80340425, -0.94247225,  0.56574075,  1.62695222,\n",
       "        0.1099537 ,  1.01576542, -0.09721071, -0.91756091, -0.48171968,\n",
       "        0.20798843,  0.50554433,  0.77693272, -1.07795697, -1.07294072,\n",
       "       -0.27868299,  0.69566652,  1.25544907,  1.43474137,  0.06420664,\n",
       "        0.18274274,  0.8670704 , -0.40206232, -0.7304444 , -1.11458678,\n",
       "       -1.05948252,  0.75249321,  0.88812291, -1.45370526])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:54:47.005366Z",
     "iopub.status.busy": "2023-07-27T04:54:47.004711Z",
     "iopub.status.idle": "2023-07-27T04:54:47.776542Z",
     "shell.execute_reply": "2023-07-27T04:54:47.775926Z"
    },
    "id": "FO0mMOYUDWFk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.16324740648269653\n",
      "cross entropy :  0.16324740648269653\n",
      "Brier score :  0.03463245555758476\n",
      "tp :  75.0\n",
      "fp :  1347.0\n",
      "tn :  55527.0\n",
      "fn :  13.0\n",
      "accuracy :  0.9761244058609009\n",
      "precision :  0.0527426153421402\n",
      "recall :  0.8522727489471436\n",
      "auc :  0.9740983247756958\n",
      "prc :  0.6931672692298889\n",
      "\n",
      "Legitimate Transactions Detected (True Negatives):  55527\n",
      "Legitimate Transactions Incorrectly Detected (False Positives):  1347\n",
      "Fraudulent Transactions Missed (False Negatives):  13\n",
      "Fraudulent Transactions Detected (True Positives):  75\n",
      "Total Fraudulent Transactions:  88\n"
     ]
    }
   ],
   "source": [
    "resampled_results = resampled_model.evaluate(test_features, test_labels,\n",
    "                                             batch_size=BATCH_SIZE, verbose=0)\n",
    "for name, value in zip(resampled_model.metrics_names, resampled_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "plot_cm(test_labels, test_predictions_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xYozM1IIITq"
   },
   "source": [
    "### Plot the ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:54:47.779819Z",
     "iopub.status.busy": "2023-07-27T04:54:47.779578Z",
     "iopub.status.idle": "2023-07-27T04:54:48.160090Z",
     "shell.execute_reply": "2023-07-27T04:54:48.159442Z"
    },
    "id": "fye_CiuYrZ1U"
   },
   "outputs": [],
   "source": [
    "plot_roc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\n",
    "plot_roc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\n",
    "plot_roc(\"Train Weighted\", train_labels, train_predictions_weighted, color=colors[1])\n",
    "plot_roc(\"Test Weighted\", test_labels, test_predictions_weighted, color=colors[1], linestyle='--')\n",
    "plot_roc(\"Train Resampled\", train_labels, train_predictions_resampled, color=colors[2])\n",
    "plot_roc(\"Test Resampled\", test_labels, test_predictions_resampled, color=colors[2], linestyle='--')\n",
    "plt.legend(loc='lower right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vayGnv0VOe_v"
   },
   "source": [
    "### Plot the AUPRC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:54:48.163919Z",
     "iopub.status.busy": "2023-07-27T04:54:48.163399Z",
     "iopub.status.idle": "2023-07-27T04:54:48.582548Z",
     "shell.execute_reply": "2023-07-27T04:54:48.581887Z"
    },
    "id": "wgWXQ8aeOhCZ"
   },
   "outputs": [],
   "source": [
    "plot_prc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\n",
    "plot_prc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\n",
    "\n",
    "plot_prc(\"Train Weighted\", train_labels, train_predictions_weighted, color=colors[1])\n",
    "plot_prc(\"Test Weighted\", test_labels, test_predictions_weighted, color=colors[1], linestyle='--')\n",
    "\n",
    "plot_prc(\"Train Resampled\", train_labels, train_predictions_resampled, color=colors[2])\n",
    "plot_prc(\"Test Resampled\", test_labels, test_predictions_resampled, color=colors[2], linestyle='--')\n",
    "plt.legend(loc='lower right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model as a `.keras` zip archive.\n",
    "tf.keras.models.save_model(\n",
    "    resampled_model,\n",
    "    'models/fraud2.keras',\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")\n",
    "\n",
    "resampled_model.save('models/fraud.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3o3f0ywl8uqW"
   },
   "source": [
    "## Applying this tutorial to your problem\n",
    "\n",
    "Imbalanced data classification is an inherently difficult task since there are so few samples to learn from. You should always start with the data first and do your best to collect as many samples as possible and give substantial thought to what features may be relevant so the model can get the most out of your minority class. At some point your model may struggle to improve and yield the results you want, so it is important to keep in mind the context of your problem and the trade offs between different types of errors."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "imbalanced_data.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
